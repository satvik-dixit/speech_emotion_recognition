{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/datasets_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziyDk4cxk1wh"
      },
      "source": [
        "# Comparing results on multiple datasets\n",
        "\n",
        "A demo for comparing results obtained using multiple datasets. For theis notebook, we use 6 open-source speech emotion datasets:\n",
        "- Dataset 1: CaFE (French)\n",
        "- Dataset 2: EmoDB (German)\n",
        "- Dataset 3: ShEMO (Persian)\n",
        "- Dataset 4: RAVDESS (English)\n",
        "- Dataset 5: CREMA-D (English)\n",
        "- Dataset 6: SAVEE (British English)\n",
        "\n",
        "We look at the results obtained by using Deep Learning based features (hybrid BYOL-S) and DSP based features (openSMILE comPare and openSMILE egemaps) on logistic regression, SVM, random forest classification\n",
        "\n",
        "Lets start by importing a few packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B48qMjEB-CLk"
      },
      "source": [
        "### Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hed_5ILyX0ia",
        "outputId": "99b0d4e6-e1a4-4c78-cdd2-e39e15857cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 496 kB 17.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 11 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 74.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 546 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 57.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 45.7 MB/s \n",
            "\u001b[?25h  Building wheel for hyperpyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 13.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.6 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 14.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 635 kB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 167 kB 73.8 MB/s \n",
            "\u001b[?25h  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q speechbrain\n",
        "!pip install -q  transformers\n",
        "!git clone -q https://github.com/GasserElbanna/serab-byols.git\n",
        "!python3 -m pip install -q -e ./serab-byols\n",
        "\n",
        "!pip install -q tqdm==4.60.0\n",
        "!pip install -q opensmile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "2r74_jiSWxp9",
        "outputId": "ef56fc84-2c91-4176-b035-556ba4ed125f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b72538d3-0978-4bd0-90ee-47ff849dabcf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b72538d3-0978-4bd0-90ee-47ff849dabcf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving utilities.py to utilities.py\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d233d9c-a2cb-47d7-9cf9-74e2718c86b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5d233d9c-a2cb-47d7-9cf9-74e2718c86b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "files.upload()\n",
        "\n",
        "# Name directory\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTY1RZ4UwCsG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from random import sample\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "import torch\n",
        "import opensmile\n",
        "import serab_byols\n",
        "from transformers import Wav2Vec2Model, HubertModel\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from utilities import load_audio_files, audio_embeddings_model, audio_embeddings, speaker_normalisation, split_train_test, get_hyperparams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjn_XyzhFIr7"
      },
      "source": [
        "### Defining a function for the pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gplJTSNPBv7e"
      },
      "outputs": [],
      "source": [
        "results = {'EmoDB': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'CaFE': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'ShEMO': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'CREMA-D': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'RAVDESS': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'SAVEE': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "      \n",
        "logistic_regression_results = copy.deepcopy(results)\n",
        "support_vector_machine_results = copy.deepcopy(results)\n",
        "random_forest_classifier_results = copy.deepcopy(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvmZ0RwTDXCY"
      },
      "outputs": [],
      "source": [
        "# Defining a function for all steps \n",
        "\n",
        "def pipeline(audio_list, speakers, labels, model_names, dataset = None, summary_table = None):\n",
        "  '''\n",
        "  Loads and resamples audio files \n",
        "  \n",
        "  Parameters\n",
        "  ------------\n",
        "  audio_files: string\n",
        "      The paths of the wav files \n",
        "  resampling_frequency: integer\n",
        "      The frequency which all audios will be resampled to\n",
        "  audio_list: list \n",
        "      The list of torch tensors of audios to which more audios need too be added, empty by default\n",
        "\n",
        "  Returns\n",
        "  ------------\n",
        "  audio_list: list\n",
        "      A list of torch tensors, one array for each audio file\n",
        "\n",
        "  '''\n",
        "  for model_name in model_names:\n",
        "    print('MODEL: {}'.format(model_name))\n",
        "\n",
        "    # Embeddings Extraction\n",
        "    model = audio_embeddings_model(model_name = model_name)\n",
        "    embeddings_array = audio_embeddings(audio_list, model_name=model_name, model=model)\n",
        "    print('embeddings_array shape: {}'.format(embeddings_array.shape))\n",
        "\n",
        "    # Speaker Normalisation\n",
        "    normalised_embeddings = speaker_normalisation(embeddings_array, speakers)\n",
        "    print('normalised_embeddings shape: {}'.format(normalised_embeddings.shape))\n",
        "    columnwise_mean = torch.mean(normalised_embeddings, 0)\n",
        "    if torch.all(columnwise_mean < 10**(-6)):\n",
        "      print('PASSED: All means are less than 10**-6')\n",
        "    else:\n",
        "      print('FAILED: All means are NOT less than 10**-6')\n",
        "\n",
        "    # Train Test Splitting\n",
        "    X_train, X_test, y_train, y_test = split_train_test(normalised_embeddings, labels, speakers, test_size = 0.30)\n",
        "    print('X_train shape: {}'.format(X_train.shape))\n",
        "    print('X_test shape: {}'.format(X_test.shape))\n",
        "    print('y_train len: {}'.format(len(y_train)))\n",
        "    print('y_test len: {}'.format(len(y_test)))\n",
        "    print()\n",
        "\n",
        "    # Getting hyperparameters and checking max_recall\n",
        "    print('Logistic Regression:')\n",
        "    classifier = LogisticRegression()\n",
        "    parameters = {'penalty' : ['l1', 'l2'], 'C': np.logspace(-3,1,3), 'solver': ['lbfgs', 'sag']}\n",
        "    summary_table['Logistic Regression'][model_name] = logistic_regression_results[dataset][model_name] = np.round(100*get_hyperparams(X_train, X_test, y_train, y_test, classifier, parameters),1)\n",
        "    print('Support Vector Machine:')\n",
        "    classifier = SVC()\n",
        "    parameters = {'C': np.logspace(-2,4,4), 'gamma': np.logspace(-5,-3,5), 'kernel':['rbf']}\n",
        "    summary_table['Support Vector Machine'][model_name] = support_vector_machine_results[dataset][model_name] = np.round(100*get_hyperparams(X_train, X_test, y_train, y_test, classifier, parameters),1)\n",
        "    print('Random Forest Classifier:')\n",
        "    classifier = RandomForestClassifier()\n",
        "    parameters = {'n_estimators' : [50, 100, 200], 'max_features' : ['auto', 'log2', 'sqrt'], 'bootstrap' : [False]}\n",
        "    summary_table['Random Forest Classification'][model_name] = random_forest_classifier_results[dataset][model_name] = np.round(100*get_hyperparams(X_train, X_test, y_train, y_test, classifier, parameters),1)\n",
        "    print()\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I0sxA2JRzsC"
      },
      "source": [
        "# Dataset: Canadian French Emotion (CaFE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Details:\n",
        "- French (Canadian)\n",
        "- 936 recording\n",
        "- 12 speakers (6 females + 6 males)\n",
        "- 7 emotions: happy, sad, angry, fearful, surprise, disgust and neutral\n",
        "\n",
        "### References:\n",
        "- Dataset: https://zenodo.org/record/1478765#.YvyXfexBy3I\n",
        "- Paper: https://www.researchgate.net/publication/326022359_A_canadian_french_emotional_speech_dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "GEKRCww2X80-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading CaFE dataset and extracting metadata"
      ],
      "metadata": {
        "id": "zwoXwXuSeql4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "433AGNvofvBz",
        "outputId": "206b06e2-8173-47be-80ff-9ae7b57f222b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 936\n",
            "Number of speaker classes: 12\n",
            "Speaker classes: {'03', '04', '09', '02', '12', '08', '01', '07', '11', '06', '10', '05'}\n",
            "Number of speakers: 936\n",
            "Number of label classes: 7\n",
            "Label classes: {'J', 'T', 'P', 'C', 'S', 'D', 'N'}\n",
            "Number of labels: 936\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! wget -q https://zenodo.org/record/1478765/files/CaFE_48k.zip?download=1\n",
        "! unzip -q CaFE_48k.zip?download=1 -d /content/cafe\n",
        "\n",
        "# Select all the audio files\n",
        "audios = []\n",
        "for file in Path('/content/cafe').glob(\"**/*.wav\"):\n",
        "    if not file.is_file(): \n",
        "        continue\n",
        "    audios.append(str(file))\n",
        "\n",
        "# Load and resample audio files\n",
        "audio_list = load_audio_files(audios, resampling_frequency=16000)\n",
        "\n",
        "# Making speakers list and labels list \n",
        "speakers = []\n",
        "labels = []\n",
        "for audio_file in audios:\n",
        "  file_name = audio_file.split('/')[-1]\n",
        "  speakers.append(file_name.split('-')[0])\n",
        "  labels.append(file_name.split('-')[1])\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print('Number of audio files: {}'.format(len(audio_list)))\n",
        "print('Number of speaker classes: {}'.format(len(set(speakers))))\n",
        "print('Speaker classes: {}'.format(set(speakers)))\n",
        "print('Number of speakers: {}'.format(len(speakers)))\n",
        "print('Number of label classes: {}'.format(len(set(labels))))\n",
        "print('Label classes: {}'.format(set(labels)))\n",
        "print('Number of labels: {}'.format(len(labels)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata:\n",
        "Speakers: (12 speakers) \n",
        "- 01 to 12\n",
        "\n",
        "Labels: (7 labels)\n",
        "\n",
        "- P: fearful\n",
        "- C: angry\n",
        "- N: Neutral\n",
        "- D: disgust\n",
        "- J: happy\n",
        "- S: surprise\n",
        "- T: sad"
      ],
      "metadata": {
        "id": "uiLlg8Gxlbz2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X64mO8pifvB0"
      },
      "source": [
        "### Getting max_recall of all the models on CaFE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMTyqSIwjrj7"
      },
      "outputs": [],
      "source": [
        "summary_table = {'Logistic Regression': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Support Vector Machine': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Random Forest Classification': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo63o7iBfvB0",
        "outputId": "a3ced2c0-e0b8-443e-c112-fb509270c937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: hybrid_byols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings...: 100%|██████████| 936/936 [01:12<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([936, 2048])\n",
            "normalised_embeddings shape: torch.Size([936, 2048])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([702, 2048])\n",
            "X_test shape: torch.Size([234, 2048])\n",
            "y_train len: 702\n",
            "y_test len: 234\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.727099567099567\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.7341269841269841\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.7105009276437848\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.00031622776601683794, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.75\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.6494248608534321\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'auto', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6746031746031745\n",
            "\n",
            "\n",
            "MODEL: compare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 936/936 [02:08<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([936, 6373])\n",
            "normalised_embeddings shape: torch.Size([936, 6373])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([702, 6373])\n",
            "X_test shape: torch.Size([234, 6373])\n",
            "y_train len: 702\n",
            "y_test len: 234\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.6374644403215832\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.6865079365079365\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.6320964749536178\n",
            "Best Parameters: {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.6785714285714286\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.5961162646876932\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6230158730158729\n",
            "\n",
            "\n",
            "MODEL: egemaps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 936/936 [02:31<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([936, 88])\n",
            "normalised_embeddings shape: torch.Size([936, 88])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([702, 88])\n",
            "X_test shape: torch.Size([234, 88])\n",
            "y_train len: 702\n",
            "y_test len: 234\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.5955720470006185\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.611111111111111\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.5840940012368584\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.5674603174603174\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.6008781694495979\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.5714285714285714\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['hybrid_byols', 'compare', 'egemaps']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'CaFE', summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CaFE Results"
      ],
      "metadata": {
        "id": "Htmdv2XaeE94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "fCkYozHXodUz",
        "outputId": "29a33486-fae6-4351-c596-3c02488cefa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Logistic Regression  Support Vector Machine  \\\n",
              "hybrid_byols                 73.4                    75.0   \n",
              "compare                      68.7                    67.9   \n",
              "egemaps                      61.1                    56.7   \n",
              "\n",
              "              Random Forest Classification  \n",
              "hybrid_byols                          67.5  \n",
              "compare                               62.3  \n",
              "egemaps                               57.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65bad89a-2f26-4505-af0e-9acc8d58570d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Random Forest Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>73.4</td>\n",
              "      <td>75.0</td>\n",
              "      <td>67.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>68.7</td>\n",
              "      <td>67.9</td>\n",
              "      <td>62.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>61.1</td>\n",
              "      <td>56.7</td>\n",
              "      <td>57.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65bad89a-2f26-4505-af0e-9acc8d58570d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65bad89a-2f26-4505-af0e-9acc8d58570d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65bad89a-2f26-4505-af0e-9acc8d58570d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df = pd.DataFrame(summary_table)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnkwbFe5GgRT"
      },
      "source": [
        "# Dataset: Persian Speech Emotion Detection Dataset (ShEMO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details:\n",
        "- Persian\n",
        "- 3000 semi-natural utterances\n",
        "- 87 speakers\n",
        "- 6 emotions: anger, fear, happiness, sadness, neutral and surprise\n",
        "\n",
        "### References:\n",
        "- Dataset: https://github.com/mansourehk/ShEMO\n",
        "- Paper: https://link.springer.com/article/10.1007/s10579-018-9427-x\n",
        "\n"
      ],
      "metadata": {
        "id": "unc7WsAFZAQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading ShEMO dataset and extracting metadata"
      ],
      "metadata": {
        "id": "9rqXigtVfFP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLh5Gtma3YrD",
        "outputId": "533acc88-855f-45bb-9863-278f6638b877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 3000\n",
            "Number of speaker classes: 87\n",
            "Speaker classes: {'85', '08', '83', '39', '79', '70', '28', '17', '51', '71', '35', '48', '33', '86', '15', '52', '19', '76', '63', '77', '16', '31', '36', '69', '22', '09', '55', '47', '43', '67', '23', '03', '56', '21', '38', '06', '11', '18', '29', '50', '59', '72', '13', '42', '20', '81', '75', '10', '73', '58', '30', '14', '37', '60', '04', '24', '25', '05', '12', '44', '80', '45', '57', '62', '46', '78', '27', '68', '53', '65', '26', '84', '49', '02', '61', '41', '01', '07', '87', '34', '64', '74', '54', '66', '82', '40', '32'}\n",
            "Number of speakers: 3000\n",
            "Number of label classes: 6\n",
            "Label classes: {'F', 'W', 'S', 'N', 'A', 'H'}\n",
            "Number of labels: 3000\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! kaggle datasets download -q -d mansourehk/shemo-persian-speech-emotion-detection-database\n",
        "! unzip -q shemo-persian-speech-emotion-detection-database.zip -d shemo;\n",
        "\n",
        "# Select all the audio files\n",
        "audios = []\n",
        "for file in Path('/content/shemo').glob(\"**/*.wav\"):\n",
        "    if not file.is_file(): \n",
        "        continue\n",
        "    audios.append(str(file))\n",
        "\n",
        "# Load and resample audio files\n",
        "audio_list = load_audio_files(audios, resampling_frequency=16000)\n",
        "\n",
        "# Making speakers list and labels list \n",
        "speakers = []\n",
        "labels = []\n",
        "for audio_file in audios:\n",
        "  file_name = audio_file.split('/')[4]\n",
        "  speakers.append(file_name[4:6])\n",
        "  labels.append(file_name[3])\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print('Number of audio files: {}'.format(len(audio_list)))\n",
        "print('Number of speaker classes: {}'.format(len(set(speakers))))\n",
        "print('Speaker classes: {}'.format(set(speakers)))\n",
        "print('Number of speakers: {}'.format(len(speakers)))\n",
        "print('Number of label classes: {}'.format(len(set(labels))))\n",
        "print('Label classes: {}'.format(set(labels)))\n",
        "print('Number of labels: {}'.format(len(labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Metadata:\n",
        "Speakers: (87 speakers) \n",
        "- 01 to 87 \n",
        "\n",
        "Labels: (6 labels)\n",
        "- A: anger \n",
        "- F: fear\n",
        "- H: happiness\n",
        "- N: neutral\n",
        "- S: sadness\n",
        "- W: surprise"
      ],
      "metadata": {
        "id": "AFjEQRX6l2Fm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciOZGXJ9Y2GL"
      },
      "source": [
        "### Getting max_recall of all the models on ShEMO\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECBMYofUopJX"
      },
      "outputs": [],
      "source": [
        "summary_table = {'Logistic Regression': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Support Vector Machine': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Random Forest Classification': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzJRvk5gY2GM",
        "outputId": "7925886e-5547-432b-fc7f-0ea0d89e1c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: hybrid_byols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings...: 100%|██████████| 3000/3000 [04:01<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([3000, 2048])\n",
            "normalised_embeddings shape: torch.Size([3000, 2048])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([1975, 2048])\n",
            "X_test shape: torch.Size([1025, 2048])\n",
            "y_train len: 1975\n",
            "y_test len: 1025\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.5923591517600233\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.5591476916343564\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.5854103433373448\n",
            "Best Parameters: {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.5474865785406321\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.4478009617998346\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'auto', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.42086211193159045\n",
            "\n",
            "\n",
            "MODEL: compare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [06:52<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([3000, 6373])\n",
            "normalised_embeddings shape: torch.Size([3000, 6373])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([1942, 6373])\n",
            "X_test shape: torch.Size([1058, 6373])\n",
            "y_train len: 1942\n",
            "y_test len: 1058\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.5659432304836564\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.5200994465037481\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.5295765668136451\n",
            "Best Parameters: {'C': 100.0, 'gamma': 3.1622776601683795e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.4922373479821831\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.42344982038646817\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.40061124914876095\n",
            "\n",
            "\n",
            "MODEL: egemaps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [08:03<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([3000, 88])\n",
            "normalised_embeddings shape: torch.Size([3000, 88])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([1967, 88])\n",
            "X_test shape: torch.Size([1033, 88])\n",
            "y_train len: 1967\n",
            "y_test len: 1033\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.4613138812155073\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.5022154836465113\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.4474338675953378\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.49504624588942175\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.41735865007082057\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'auto', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.45268220280022553\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['hybrid_byols', 'compare', 'egemaps']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'ShEMO', summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ShEMO Results"
      ],
      "metadata": {
        "id": "ds1M1luJfSpG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O_AH-gco1R3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "df7167b9-cda8-4d16-cc48-289ca533a521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Logistic Regression  Support Vector Machine  \\\n",
              "hybrid_byols                 55.9                    54.7   \n",
              "compare                      52.0                    49.2   \n",
              "egemaps                      50.2                    49.5   \n",
              "\n",
              "              Random Forest Classification  \n",
              "hybrid_byols                          42.1  \n",
              "compare                               40.1  \n",
              "egemaps                               45.3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be3fae06-65c9-48a8-90cb-508cc30a0398\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Random Forest Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>55.9</td>\n",
              "      <td>54.7</td>\n",
              "      <td>42.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>52.0</td>\n",
              "      <td>49.2</td>\n",
              "      <td>40.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>50.2</td>\n",
              "      <td>49.5</td>\n",
              "      <td>45.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be3fae06-65c9-48a8-90cb-508cc30a0398')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be3fae06-65c9-48a8-90cb-508cc30a0398 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be3fae06-65c9-48a8-90cb-508cc30a0398');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df = pd.DataFrame(summary_table)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwXMPk6AG7O-"
      },
      "source": [
        "# Dataset: EmoDB "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details:\n",
        "- German\n",
        "- 800 recordings\n",
        "- 10 actors (5 males and 5 females)\n",
        "- 7 emotions: anger, neutral, fear, boredom, happiness, sadness, disgust\n",
        "\n",
        "### References:\n",
        "- Dataset: http://emodb.bilderbar.info/index-1280.html\n",
        "- Paper: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.8506&rep=rep1&type=pdf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VXtBAxwBhIwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading EmoDB dataset and extracting metadata"
      ],
      "metadata": {
        "id": "gfmSyZFifdIN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9Jncl071Q_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ec2cf5-ebb7-450d-9d0c-c009946a7a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 535\n",
            "Number of speaker classes: 10\n",
            "Speaker classes: {3, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
            "Number of speakers: 535\n",
            "Number of label classes: 7\n",
            "Label classes: {'F', 'T', 'W', 'E', 'L', 'N', 'A'}\n",
            "Number of labels: 535\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! kaggle datasets download -q -d piyushagni5/berlin-database-of-emotional-speech-emodb\n",
        "! unzip -q berlin-database-of-emotional-speech-emodb.zip\n",
        "\n",
        "# Load and resample audio files\n",
        "audio_files = glob(os.path.join('/content/wav','*.wav'))\n",
        "audio_list= load_audio_files(audio_files, resampling_frequency=16000)\n",
        "\n",
        "# Making speakers list and labels list \n",
        "speakers = []\n",
        "labels = []\n",
        "for audio_file in audio_files:\n",
        "  file_name = audio_file.split('/')[3]\n",
        "  speakers.append(int(file_name[:2]))\n",
        "  labels.append(file_name[5:6])\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print('Number of audio files: {}'.format(len(audio_list)))\n",
        "print('Number of speaker classes: {}'.format(len(set(speakers))))\n",
        "print('Speaker classes: {}'.format(set(speakers)))\n",
        "print('Number of speakers: {}'.format(len(speakers)))\n",
        "print('Number of label classes: {}'.format(len(set(labels))))\n",
        "print('Label classes: {}'.format(set(labels)))\n",
        "print('Number of labels: {}'.format(len(labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata:\n",
        "Speakers: (10 speakers) \n",
        "- 03 - male, 31 years old\n",
        "- 08 - female, 34 years\n",
        "- 09 - female, 21 years\n",
        "- 10 - male, 32 years\n",
        "- 11 - male, 26 years\n",
        "- 12 - male, 30 years\n",
        "- 13 - female, 32 years\n",
        "- 14 - female, 35 years\n",
        "- 15 - male, 25 years\n",
        "- 16 - female, 31 years\n",
        "\n",
        "Labels: (7 labels)\n",
        "- T: sadness \n",
        "- F: happiness\n",
        "- E: disgust\n",
        "- W: anger\n",
        "- A: fear\n",
        "- L: boredom\n",
        "- N: neutral"
      ],
      "metadata": {
        "id": "0BW31R6jmGpe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTy9hdXlhSI7"
      },
      "source": [
        "### Getting max_recall of all the models on EmoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty9Q1xn_oqwx"
      },
      "outputs": [],
      "source": [
        "summary_table = {'Logistic Regression': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Support Vector Machine': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Random Forest Classification': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZGcj5eVhSJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6c1759-feb1-4949-d772-1747e2548f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: hybrid_byols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings...: 100%|██████████| 535/535 [00:27<00:00, 19.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([535, 2048])\n",
            "normalised_embeddings shape: torch.Size([535, 2048])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([371, 2048])\n",
            "X_test shape: torch.Size([164, 2048])\n",
            "y_train len: 371\n",
            "y_test len: 164\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.8920336555674903\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.8673666568076506\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.9039384174722521\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.8485024154589372\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.8046640410550185\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.7469683525584146\n",
            "\n",
            "\n",
            "MODEL: compare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 535/535 [00:58<00:00,  9.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([535, 6373])\n",
            "normalised_embeddings shape: torch.Size([535, 6373])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([351, 6373])\n",
            "X_test shape: torch.Size([184, 6373])\n",
            "y_train len: 351\n",
            "y_test len: 184\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.8468769325912182\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.8284103381929467\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.8472758194186767\n",
            "Best Parameters: {'C': 100.0, 'gamma': 3.1622776601683795e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.858094441790094\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.8141104926819211\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.7439184185379837\n",
            "\n",
            "\n",
            "MODEL: egemaps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 535/535 [01:04<00:00,  8.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([535, 88])\n",
            "normalised_embeddings shape: torch.Size([535, 88])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([360, 88])\n",
            "X_test shape: torch.Size([175, 88])\n",
            "y_train len: 360\n",
            "y_test len: 175\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.7751672184025125\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.756169519461445\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.7708522196757491\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.00031622776601683794, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.7624359100756616\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.7486227824463119\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'log2', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6993356287145108\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['hybrid_byols', 'compare', 'egemaps']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'EmoDB', summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EmoDB Results"
      ],
      "metadata": {
        "id": "d5KvoHJxflcU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUNFnu8Ao2tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "89e74e54-156c-492a-899d-5f952000eb3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Logistic Regression  Support Vector Machine  \\\n",
              "hybrid_byols                 86.7                    84.9   \n",
              "compare                      82.8                    85.8   \n",
              "egemaps                      75.6                    76.2   \n",
              "\n",
              "              Random Forest Classification  \n",
              "hybrid_byols                          74.7  \n",
              "compare                               74.4  \n",
              "egemaps                               69.9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af1705eb-29a4-4216-9812-9f4fca2176db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Random Forest Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>86.7</td>\n",
              "      <td>84.9</td>\n",
              "      <td>74.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>82.8</td>\n",
              "      <td>85.8</td>\n",
              "      <td>74.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>75.6</td>\n",
              "      <td>76.2</td>\n",
              "      <td>69.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af1705eb-29a4-4216-9812-9f4fca2176db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af1705eb-29a4-4216-9812-9f4fca2176db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af1705eb-29a4-4216-9812-9f4fca2176db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df = pd.DataFrame(summary_table)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRzA2MjjHi4D"
      },
      "source": [
        "# Dataset: Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details:\n",
        "- English\n",
        "- 7356 recordings\n",
        "- 24 actors (12 female, 12 male)\n",
        "- 8 emotions: neutral, calm, happy, sad, angry, fearful, surprise, and disgust\n",
        "\n",
        "### References:\n",
        "- Dataset: https://zenodo.org/record/1188976#.YvyPHexBy3K\n",
        "- Paper: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391\n",
        "\n"
      ],
      "metadata": {
        "id": "BI-B9wDpjGQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading RAVDESS dataset and extracting metadata"
      ],
      "metadata": {
        "id": "NusuOz_MgCX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnP07Wkg-1ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7c29a4-4584-45b5-f088-7535b1adeac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 1440\n",
            "Number of speaker classes: 24\n",
            "Speaker classes: {'16', '08', '22', '09', '02', '17', '01', '07', '14', '23', '03', '04', '24', '15', '21', '11', '06', '18', '05', '12', '19', '13', '20', '10'}\n",
            "Number of speakers: 1440\n",
            "Number of label classes: 8\n",
            "Label classes: {'03', '04', '02', '08', '01', '07', '06', '05'}\n",
            "Number of labels: 1440\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! kaggle datasets download -q -d uwrfkaggler/ravdess-emotional-speech-audio\n",
        "! unzip -q ravdess-emotional-speech-audio.zip -d '/content/ravdess'\n",
        "\n",
        "# Select all the audio files\n",
        "audios = []\n",
        "for file in Path('/content/ravdess/audio_speech_actors_01-24').glob(\"**/*.wav\"):\n",
        "    if not file.is_file(): \n",
        "        continue\n",
        "    audios.append(str(file))\n",
        "\n",
        "# Load and resample audio files\n",
        "audio_list = load_audio_files(audios, resampling_frequency=16000)\n",
        "\n",
        "# Making speakers list and labels list \n",
        "speakers = []\n",
        "labels = []\n",
        "for audio_file in audios:\n",
        "  file_name = audio_file.split('/')[5]\n",
        "  speakers.append(file_name[18:20])\n",
        "  labels.append(file_name[6:8])\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print('Number of audio files: {}'.format(len(audio_list)))\n",
        "print('Number of speaker classes: {}'.format(len(set(speakers))))\n",
        "print('Speaker classes: {}'.format(set(speakers)))\n",
        "print('Number of speakers: {}'.format(len(speakers)))\n",
        "print('Number of label classes: {}'.format(len(set(labels))))\n",
        "print('Label classes: {}'.format(set(labels)))\n",
        "print('Number of labels: {}'.format(len(labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata:\n",
        "Speakers: (24 speakers) \n",
        "- Odd numbered actors are male \n",
        "- Even numbered actors are female\n",
        "\n",
        "Labels: (8 labels)\n",
        "- 01 = neutral\n",
        "- 02 = calm\n",
        "- 03 = happy\n",
        "- 04 = sad\n",
        "- 05 = angry\n",
        "- 06 = fearful\n",
        "- 07 = disgust\n",
        "- 08 = surprised"
      ],
      "metadata": {
        "id": "1k52q1remRet"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvUSeKS_hXbh"
      },
      "source": [
        "### Getting max_recall of all the models on RAVDESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98sqkRd2osFg"
      },
      "outputs": [],
      "source": [
        "summary_table = {'Logistic Regression': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Support Vector Machine': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Random Forest Classification': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al6DnO6BhXbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad2ac20-2a73-4f3e-8da6-4b7d3a63e865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: hybrid_byols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings...: 100%|██████████| 1440/1440 [01:36<00:00, 14.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([1440, 2048])\n",
            "normalised_embeddings shape: torch.Size([1440, 2048])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([1020, 2048])\n",
            "X_test shape: torch.Size([420, 2048])\n",
            "y_train len: 1020\n",
            "y_test len: 420\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.7641458078958079\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.7901785714285714\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.7702253764753765\n",
            "Best Parameters: {'C': 100.0, 'gamma': 3.1622776601683795e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.7991071428571428\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.6453220390720391\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.7098214285714286\n",
            "\n",
            "\n",
            "MODEL: compare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1440/1440 [03:01<00:00,  7.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([1440, 6373])\n",
            "normalised_embeddings shape: torch.Size([1440, 6373])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([1020, 6373])\n",
            "X_test shape: torch.Size([420, 6373])\n",
            "y_train len: 1020\n",
            "y_test len: 420\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.6615181115181115\n",
            "Best Parameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.7008928571428571\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.643574481074481\n",
            "Best Parameters: {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.6875\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.5842236467236468\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'auto', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.5870535714285714\n",
            "\n",
            "\n",
            "MODEL: egemaps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1440/1440 [03:21<00:00,  7.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([1440, 88])\n",
            "normalised_embeddings shape: torch.Size([1440, 88])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([1020, 88])\n",
            "X_test shape: torch.Size([420, 88])\n",
            "y_train len: 1020\n",
            "y_test len: 420\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.5803291615791617\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.6316964285714285\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.5926078551078551\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.00031622776601683794, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.6316964285714286\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.5597018722018722\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6026785714285714\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['hybrid_byols', 'compare', 'egemaps']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'RAVDESS', summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAVDESS Results"
      ],
      "metadata": {
        "id": "25MmtHdngH-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymogEGAvo31w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ae867ddd-2482-41f2-b142-a7c61325a0f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Logistic Regression  Support Vector Machine  \\\n",
              "hybrid_byols                 79.0                    79.9   \n",
              "compare                      70.1                    68.8   \n",
              "egemaps                      63.2                    63.2   \n",
              "\n",
              "              Random Forest Classification  \n",
              "hybrid_byols                          71.0  \n",
              "compare                               58.7  \n",
              "egemaps                               60.3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac2bce0f-3b79-4be5-b1e0-8c58c14a7ddd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Random Forest Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>79.0</td>\n",
              "      <td>79.9</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>70.1</td>\n",
              "      <td>68.8</td>\n",
              "      <td>58.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>63.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>60.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac2bce0f-3b79-4be5-b1e0-8c58c14a7ddd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac2bce0f-3b79-4be5-b1e0-8c58c14a7ddd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac2bce0f-3b79-4be5-b1e0-8c58c14a7ddd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df = pd.DataFrame(summary_table)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpGS0iS0IO4i"
      },
      "source": [
        "# Dataset: Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details:\n",
        "- English\n",
        "- 7442 clip \n",
        "- 91 actors (48 males and 43 females)\n",
        "- 6 emotions: angry, disgusted, fearful, happy, neutral, and sad\n",
        "\n",
        "### References:\n",
        "- Dataset: https://github.com/CheyneyComputerScience/CREMA-D\n",
        "- Paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5VxT9ToJlGlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading CREMA-D dataset and extracting metadata"
      ],
      "metadata": {
        "id": "9s6FxpTHgcQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvww89A5fv6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacaf44c-04e4-4f8d-fff7-4c58372d6841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 7442\n",
            "Number of speaker classes: 91\n",
            "Speaker classes: {1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023}\n",
            "Number of speakers: 7442\n",
            "Number of label classes: 6\n",
            "Label classes: {'DIS', 'HAP', 'SAD', 'ANG', 'NEU', 'FEA'}\n",
            "Number of labels: 7442\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! kaggle datasets download -q -d ejlok1/cremad\n",
        "! unzip -q cremad.zip\n",
        "\n",
        "# Load and resample audio files\n",
        "audio_files = glob(os.path.join('/content/AudioWAV','*.wav'))\n",
        "audio_list = load_audio_files(audio_files, resampling_frequency=16000)\n",
        "\n",
        "# Make speakers list and labels list \n",
        "speakers = []\n",
        "labels = []\n",
        "for audio_file in audio_files:\n",
        "  file_name = audio_file.split('/')[3]\n",
        "  speakers.append(int(file_name[:4]))\n",
        "  labels.append(file_name[9:12])\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print('Number of audio files: {}'.format(len(audio_list)))\n",
        "print('Number of speaker classes: {}'.format(len(set(speakers))))\n",
        "print('Speaker classes: {}'.format(set(speakers)))\n",
        "print('Number of speakers: {}'.format(len(speakers)))\n",
        "print('Number of label classes: {}'.format(len(set(labels))))\n",
        "print('Label classes: {}'.format(set(labels)))\n",
        "print('Number of labels: {}'.format(len(labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata:\n",
        "Speakers: (91 speakers) \n",
        "- 1001 - 1091\n",
        "\n",
        "Labels: (8 labels)\n",
        "- HAP: happy\n",
        "- ANG: angry\n",
        "- SAD: sad\n",
        "- NEU: neutral\n",
        "- FEA: fearful\n",
        "- DIS: disgusted"
      ],
      "metadata": {
        "id": "yA4_C71pmdJ9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX4u7d3hhY00"
      },
      "source": [
        "### Getting max_recall of all the models on CREMA-D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o-zxdWyotdy"
      },
      "outputs": [],
      "source": [
        "summary_table = {'Logistic Regression': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Support Vector Machine': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Random Forest Classification': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9yA1cdehY00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05b1415-046c-4a63-d75c-284dc820575f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: hybrid_byols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings...: 100%|██████████| 7442/7442 [05:51<00:00, 21.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([7442, 2048])\n",
            "normalised_embeddings shape: torch.Size([7442, 2048])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([5240, 2048])\n",
            "X_test shape: torch.Size([2202, 2048])\n",
            "y_train len: 5240\n",
            "y_test len: 2202\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.7386984092209199\n",
            "Best Parameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.7387394828421656\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.7223840995119339\n",
            "Best Parameters: {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.7212237346372405\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.636578181862441\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6407647240209683\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['hybrid_byols']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'CREMA-D', summary_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64H062h0ck_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc5fc17-fa72-48ca-891f-0290eb956ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: egemaps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7442/7442 [12:25<00:00,  9.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([7442, 88])\n",
            "normalised_embeddings shape: torch.Size([7442, 88])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([5228, 88])\n",
            "X_test shape: torch.Size([2214, 88])\n",
            "y_train len: 5228\n",
            "y_test len: 2214\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.6005416807731594\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.6100823045267489\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.6106499692433653\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.6300705467372133\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.5857512573519398\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'log2', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.5861258083480305\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['egemaps']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'CREMA-D', summary_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvWWHu0bcm-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3ef6f5-eb0b-4cc8-8853-bc705e0296b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: compare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7442/7442 [12:06<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([7442, 6373])\n",
            "normalised_embeddings shape: torch.Size([7442, 6373])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([5229, 6373])\n",
            "X_test shape: torch.Size([2213, 6373])\n",
            "y_train len: 5229\n",
            "y_test len: 2213\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.6831417705091309\n",
            "Best Parameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.7049677570833403\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.6536295909494628\n",
            "Best Parameters: {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.6837846249610955\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.6135556688609493\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6435669784482995\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['compare']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'CREMA-D', summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CREMA-D Results"
      ],
      "metadata": {
        "id": "gCDc5fDAgmMC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYRWp3buo46A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8fc26e92-fb66-4bde-db79-76a840e104de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Logistic Regression  Support Vector Machine  \\\n",
              "hybrid_byols                 73.9                    72.1   \n",
              "compare                      70.5                    68.4   \n",
              "egemaps                      61.0                    63.0   \n",
              "\n",
              "              Random Forest Classification  \n",
              "hybrid_byols                          64.1  \n",
              "compare                               64.4  \n",
              "egemaps                               58.6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6cebae8-d309-46da-834b-156cea8f350e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Random Forest Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>73.9</td>\n",
              "      <td>72.1</td>\n",
              "      <td>64.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>70.5</td>\n",
              "      <td>68.4</td>\n",
              "      <td>64.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>61.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>58.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6cebae8-d309-46da-834b-156cea8f350e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6cebae8-d309-46da-834b-156cea8f350e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6cebae8-d309-46da-834b-156cea8f350e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = pd.DataFrame(summary_table)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WJP5oglHV1g"
      },
      "source": [
        "# Dataset: Surrey Audio-Visual Expressed Emotion (SAVEE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details:\n",
        "- English (British)\n",
        "- 480 utterances \n",
        "- 4 male actors\n",
        "- 7 emotions: anger, disgust, fear, happiness, sadness, surprise and neutral\n",
        "\n",
        "### References:\n",
        "- Dataset: http://kahlan.eps.surrey.ac.uk/savee/Database.html\n",
        "- Paper: http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10_approved.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "XsPgeHownQNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading SAVEE dataset and extracting metadata"
      ],
      "metadata": {
        "id": "D6KOiUkwhT5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVxAV4Xy28bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd36608-1043-4562-c9f6-8987714c23e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 480\n",
            "Number of speaker classes: 4\n",
            "Speaker classes: {'JK', 'DC', 'KL', 'JE'}\n",
            "Number of speakers: 480\n",
            "Number of label classes: 7\n",
            "Label classes: {'d', 'f', 'h', 'n', 'a', 'sa', 'su'}\n",
            "Number of labels: 480\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! kaggle datasets download -q -d barelydedicated/savee-database\n",
        "! unzip -q savee-database.zip \n",
        "\n",
        "# Select all the audio files\n",
        "audios = []\n",
        "for file in Path('/content/AudioData').glob(\"**/*.wav\"):\n",
        "    if not file.is_file(): \n",
        "        continue\n",
        "    audios.append(str(file))\n",
        "\n",
        "# Load and resample audio files\n",
        "audio_list = load_audio_files(audios, resampling_frequency=16000)\n",
        "\n",
        "# Making speakers list and labels list \n",
        "speakers = []\n",
        "labels = []\n",
        "for audio_file in audios:\n",
        "  file_name = audio_file.split('/')[4]\n",
        "  speakers.append(audio_file.split('/')[3])\n",
        "  if file_name[0]!='s':\n",
        "    labels.append(file_name[0])\n",
        "  else:\n",
        "    labels.append(file_name[0:2])\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print('Number of audio files: {}'.format(len(audio_list)))\n",
        "print('Number of speaker classes: {}'.format(len(set(speakers))))\n",
        "print('Speaker classes: {}'.format(set(speakers)))\n",
        "print('Number of speakers: {}'.format(len(speakers)))\n",
        "print('Number of label classes: {}'.format(len(set(labels))))\n",
        "print('Label classes: {}'.format(set(labels)))\n",
        "print('Number of labels: {}'.format(len(labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata:\n",
        "Speakers: (4 speakers) \n",
        "- DC: male speaker 1\n",
        "- JE: male speaker 2\n",
        "- JK: male speaker 3\n",
        "- KL: male speaker 4\n",
        "\n",
        "Labels: (7 labels)\n",
        "\n",
        "- h: happy\n",
        "- a: anger\n",
        "- d: disgust\n",
        "- f: fear\n",
        "- sa: sadness\n",
        "- su: surprise\n",
        "- n: neutral"
      ],
      "metadata": {
        "id": "drpavghxmtuu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sweIDlX7hWgp"
      },
      "source": [
        "### Getting max_recall of all the models on SAVEE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcCQaQBBou0l"
      },
      "outputs": [],
      "source": [
        "summary_table = {'Logistic Regression': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Support Vector Machine': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0},\n",
        "        'Random Forest Classification': {'hybrid_byols': 0, 'compare': 0, 'egemaps': 0}}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLAJwd09hWgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9e28d6-a92a-406e-8d78-1b3d5dd86de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: hybrid_byols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings...: 100%|██████████| 480/480 [00:37<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([480, 2048])\n",
            "normalised_embeddings shape: torch.Size([480, 2048])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([360, 2048])\n",
            "X_test shape: torch.Size([120, 2048])\n",
            "y_train len: 360\n",
            "y_test len: 120\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.8507936507936508\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.5285714285714286\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.8857142857142856\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.5238095238095238\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.7984126984126985\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.4666666666666667\n",
            "\n",
            "\n",
            "MODEL: compare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480/480 [01:02<00:00,  7.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([480, 6373])\n",
            "normalised_embeddings shape: torch.Size([480, 6373])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([360, 6373])\n",
            "X_test shape: torch.Size([120, 6373])\n",
            "y_train len: 360\n",
            "y_test len: 120\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.680952380952381\n",
            "Best Parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "recall_macro on test_set: 0.6380952380952382\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.6555555555555557\n",
            "Best Parameters: {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.5952380952380951\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.6428571428571429\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "recall_macro on test_set: 0.5333333333333333\n",
            "\n",
            "\n",
            "MODEL: egemaps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480/480 [01:10<00:00,  6.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_array shape: torch.Size([480, 88])\n",
            "normalised_embeddings shape: torch.Size([480, 88])\n",
            "PASSED: All means are less than 10**-6\n",
            "X_train shape: torch.Size([360, 88])\n",
            "X_test shape: torch.Size([120, 88])\n",
            "y_train len: 360\n",
            "y_test len: 120\n",
            "\n",
            "Logistic Regression:\n",
            "recall_macro : 0.6444444444444445\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
            "recall_macro on test_set: 0.6523809523809525\n",
            "Support Vector Machine:\n",
            "recall_macro : 0.673015873015873\n",
            "Best Parameters: {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "recall_macro on test_set: 0.619047619047619\n",
            "Random Forest Classifier:\n",
            "recall_macro : 0.684126984126984\n",
            "Best Parameters: {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "recall_macro on test_set: 0.6476190476190476\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = ['hybrid_byols', 'compare', 'egemaps']\n",
        "pipeline(audio_list, speakers, labels, model_names, 'SAVEE', summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVEE Results"
      ],
      "metadata": {
        "id": "crg-GsV9ha3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPLK1_t_o6EH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "0ab29d0a-835d-47d7-8579-bc39fca69827"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Logistic Regression  Support Vector Machine  \\\n",
              "hybrid_byols                 52.9                    52.4   \n",
              "compare                      63.8                    59.5   \n",
              "egemaps                      65.2                    61.9   \n",
              "\n",
              "              Random Forest Classification  \n",
              "hybrid_byols                          46.7  \n",
              "compare                               53.3  \n",
              "egemaps                               64.8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7468ae82-d601-422a-8e46-34441db012cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Random Forest Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>52.9</td>\n",
              "      <td>52.4</td>\n",
              "      <td>46.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>63.8</td>\n",
              "      <td>59.5</td>\n",
              "      <td>53.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>65.2</td>\n",
              "      <td>61.9</td>\n",
              "      <td>64.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7468ae82-d601-422a-8e46-34441db012cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7468ae82-d601-422a-8e46-34441db012cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7468ae82-d601-422a-8e46-34441db012cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df = pd.DataFrame(summary_table)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gM3bQimQhq-"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression Results\n",
        "\n",
        "The recall_macro (%) on different datasets for logistic regression"
      ],
      "metadata": {
        "id": "_f_Zv4RNTJdi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDwJS5P8QmOk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "27ab6a18-55e6-4edc-bc19-6a1b98714c64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              EmoDB  CaFE  ShEMO  CREMA-D  RAVDESS  SAVEE\n",
              "hybrid_byols   86.7  73.4   55.9     73.9     79.0   52.9\n",
              "compare        82.8  68.7   52.0     70.5     70.1   63.8\n",
              "egemaps        75.6  61.1   50.2     61.0     63.2   65.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43954e32-b0c9-4705-83a5-e1c35576d199\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmoDB</th>\n",
              "      <th>CaFE</th>\n",
              "      <th>ShEMO</th>\n",
              "      <th>CREMA-D</th>\n",
              "      <th>RAVDESS</th>\n",
              "      <th>SAVEE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>86.7</td>\n",
              "      <td>73.4</td>\n",
              "      <td>55.9</td>\n",
              "      <td>73.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>52.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>82.8</td>\n",
              "      <td>68.7</td>\n",
              "      <td>52.0</td>\n",
              "      <td>70.5</td>\n",
              "      <td>70.1</td>\n",
              "      <td>63.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>75.6</td>\n",
              "      <td>61.1</td>\n",
              "      <td>50.2</td>\n",
              "      <td>61.0</td>\n",
              "      <td>63.2</td>\n",
              "      <td>65.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43954e32-b0c9-4705-83a5-e1c35576d199')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43954e32-b0c9-4705-83a5-e1c35576d199 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43954e32-b0c9-4705-83a5-e1c35576d199');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "lr_data = pd.DataFrame(logistic_regression_results)\n",
        "lr_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine Results\n",
        "\n",
        "The recall_macro (%) on different datasets for SVM"
      ],
      "metadata": {
        "id": "yBzJIudlTPTI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZNBwX36QSM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "93ee0df2-48dd-47a8-d1c0-9584b47f3499"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              EmoDB  CaFE  ShEMO  CREMA-D  RAVDESS  SAVEE\n",
              "hybrid_byols   84.9  75.0   54.7     72.1     79.9   52.4\n",
              "compare        85.8  67.9   49.2     68.4     68.8   59.5\n",
              "egemaps        76.2  56.7   49.5     63.0     63.2   61.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-390117c0-d2d1-40b9-9ef5-e7629f41c9e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmoDB</th>\n",
              "      <th>CaFE</th>\n",
              "      <th>ShEMO</th>\n",
              "      <th>CREMA-D</th>\n",
              "      <th>RAVDESS</th>\n",
              "      <th>SAVEE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>84.9</td>\n",
              "      <td>75.0</td>\n",
              "      <td>54.7</td>\n",
              "      <td>72.1</td>\n",
              "      <td>79.9</td>\n",
              "      <td>52.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>85.8</td>\n",
              "      <td>67.9</td>\n",
              "      <td>49.2</td>\n",
              "      <td>68.4</td>\n",
              "      <td>68.8</td>\n",
              "      <td>59.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>76.2</td>\n",
              "      <td>56.7</td>\n",
              "      <td>49.5</td>\n",
              "      <td>63.0</td>\n",
              "      <td>63.2</td>\n",
              "      <td>61.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-390117c0-d2d1-40b9-9ef5-e7629f41c9e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-390117c0-d2d1-40b9-9ef5-e7629f41c9e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-390117c0-d2d1-40b9-9ef5-e7629f41c9e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "svm_data = pd.DataFrame(support_vector_machine_results)\n",
        "svm_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classification Results\n",
        "\n",
        "The recall_macro (%) on different datasets for random forest classification"
      ],
      "metadata": {
        "id": "HAh3W7IVTVs-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkdSC7z8QSPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "badd8fd3-89ef-4e37-e47d-fe1b47f60dda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              EmoDB  CaFE  ShEMO  CREMA-D  RAVDESS  SAVEE\n",
              "hybrid_byols   74.7  67.5   42.1     64.1     71.0   46.7\n",
              "compare        74.4  62.3   40.1     64.4     58.7   53.3\n",
              "egemaps        69.9  57.1   45.3     58.6     60.3   64.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-634b9e75-d84d-4056-9950-999bfe375a0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmoDB</th>\n",
              "      <th>CaFE</th>\n",
              "      <th>ShEMO</th>\n",
              "      <th>CREMA-D</th>\n",
              "      <th>RAVDESS</th>\n",
              "      <th>SAVEE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hybrid_byols</th>\n",
              "      <td>74.7</td>\n",
              "      <td>67.5</td>\n",
              "      <td>42.1</td>\n",
              "      <td>64.1</td>\n",
              "      <td>71.0</td>\n",
              "      <td>46.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compare</th>\n",
              "      <td>74.4</td>\n",
              "      <td>62.3</td>\n",
              "      <td>40.1</td>\n",
              "      <td>64.4</td>\n",
              "      <td>58.7</td>\n",
              "      <td>53.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egemaps</th>\n",
              "      <td>69.9</td>\n",
              "      <td>57.1</td>\n",
              "      <td>45.3</td>\n",
              "      <td>58.6</td>\n",
              "      <td>60.3</td>\n",
              "      <td>64.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-634b9e75-d84d-4056-9950-999bfe375a0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-634b9e75-d84d-4056-9950-999bfe375a0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-634b9e75-d84d-4056-9950-999bfe375a0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "rfc_data = pd.DataFrame(random_forest_classifier_results)\n",
        "rfc_data\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "B48qMjEB-CLk",
        "Wjn_XyzhFIr7",
        "_I0sxA2JRzsC",
        "X64mO8pifvB0",
        "VnkwbFe5GgRT",
        "SwXMPk6AG7O-",
        "sRzA2MjjHi4D",
        "cpGS0iS0IO4i",
        "6WJP5oglHV1g"
      ],
      "name": "datasets_demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLihOXA/h1tWFvUb57gF5K",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}