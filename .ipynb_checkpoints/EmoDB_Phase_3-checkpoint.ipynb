{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/EmoDB_Phase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziyDk4cxk1wh"
      },
      "source": [
        "# EmoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B48qMjEB-CLk"
      },
      "source": [
        "## Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hed_5ILyX0ia",
        "outputId": "5e03c8c7-ee28-48d8-ae64-9079007a52a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.7/dist-packages (0.5.12)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.11.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.8.1)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.60.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.60.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "fatal: destination path 'serab-byols' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/serab-byols\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.8.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.51.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.11.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (4.60.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.9)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.4.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (0.10.3.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.7.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (0.3.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->serab-byols==0.0.0) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->serab-byols==0.0.0) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->serab-byols==0.0.0) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->serab-byols==0.0.0) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->serab-byols==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->serab-byols==0.0.0) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->serab-byols==0.0.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->serab-byols==0.0.0) (2.21)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->serab-byols==0.0.0) (4.1.1)\n",
            "Installing collected packages: serab-byols\n",
            "  Attempting uninstall: serab-byols\n",
            "    Found existing installation: serab-byols 0.0.0\n",
            "    Can't uninstall 'serab-byols'. No files were found to uninstall.\n",
            "  Running setup.py develop for serab-byols\n",
            "Successfully installed serab-byols-0.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm==4.60.0 in /usr/local/lib/python3.7/dist-packages (4.60.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opensmile in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: audinterface>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from opensmile) (0.9.0)\n",
            "Requirement already satisfied: audobject>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from opensmile) (0.7.3)\n",
            "Requirement already satisfied: audformat<2.0.0,>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from audinterface>=0.7.0->opensmile) (0.14.3)\n",
            "Requirement already satisfied: audresample<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from audinterface>=0.7.0->opensmile) (1.1.0)\n",
            "Requirement already satisfied: iso-639 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (0.4.5)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (6.0)\n",
            "Requirement already satisfied: pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.3.5)\n",
            "Requirement already satisfied: iso3166 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.1.1)\n",
            "Requirement already satisfied: audeer<2.0.0,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.18.0)\n",
            "Requirement already satisfied: audiofile>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from audeer<2.0.0,>=1.18.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (4.60.0)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.4.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (0.10.3.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from audobject>=0.6.1->opensmile) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain\n",
        "!pip install transformers\n",
        "!git clone https://github.com/GasserElbanna/serab-byols.git\n",
        "!python3 -m pip install -e ./serab-byols\n",
        "\n",
        "!pip install tqdm==4.60.0\n",
        "!pip install opensmile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aTY1RZ4UwCsG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import serab_byols\n",
        "import opensmile\n",
        "from transformers import Wav2Vec2Model, HubertModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import sample\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzKQQopg1I09"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import os\n",
        "from glob import glob\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "2r74_jiSWxp9",
        "outputId": "75caaceb-5b8f-4763-980d-19bd8c47bc85"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afd2f9f2-3177-44a2-9a24-59d196cf2f2a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afd2f9f2-3177-44a2-9a24-59d196cf2f2a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Name directory\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW6Yipn9MTLg"
      },
      "source": [
        "# Phase 1 Functions: Loading and resampling audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae5OWFUETeZC"
      },
      "outputs": [],
      "source": [
        "# Defining function for loading and resampling audio files\n",
        "\n",
        "def load_audio_files(audio_files, resampling_frequency=16000, audio_list=None):\n",
        "    '''\n",
        "    Loads and resamples audio files \n",
        "    \n",
        "    Parameters\n",
        "    ------------\n",
        "    audio_files: string\n",
        "        The paths of the wav files \n",
        "    resampling_frequency: integer\n",
        "        The frequency which all audios will be resampled to\n",
        "    audio_list: list of torch arrays of audios to which more audios need too be added, empty by default\n",
        "\n",
        "    Returns\n",
        "    ------------\n",
        "    audio_list: list of torch arrays\n",
        "        A list of torch arrays, one array for each audio file\n",
        "        \n",
        "    '''\n",
        "\n",
        "    # Making audio_list\n",
        "    if audio_list is None:\n",
        "      audio_list = []\n",
        "\n",
        "    # Resampling\n",
        "    for audio in audio_files:\n",
        "        signal, fs = librosa.load(audio, sr=resampling_frequency)\n",
        "        audio_list.append(torch.from_numpy(signal))\n",
        "        \n",
        "    return audio_list\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0kPY4usMGbA"
      },
      "source": [
        "# Phase 2 Functions: Embedding Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP3vG54u9D-r"
      },
      "source": [
        "## Audio Embeddings Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCNer33gwaMl"
      },
      "outputs": [],
      "source": [
        "def audio_embeddings_model(model_name):\n",
        "  '''\n",
        "  Generates model for embedding extraction \n",
        "  \n",
        "  Parameters\n",
        "  ------------\n",
        "  mode_name: string\n",
        "      The model to used, could be 'wav2vec', 'hubert' or 'hybrid_byols'\n",
        "\n",
        "  Returns\n",
        "  ------------\n",
        "  model: object\n",
        "\n",
        "  '''\n",
        "  if model_name=='wav2vec2':\n",
        "    model_hub = 'facebook/wav2vec2-large-960h-lv60-self'\n",
        "    model = Wav2Vec2Model.from_pretrained(model_hub)\n",
        "  elif model_name=='hubert':\n",
        "    model_hub = 'facebook/hubert-xlarge-ll60k'\n",
        "    model = HubertModel.from_pretrained(model_hub)\n",
        "  elif model_name=='hybrid_byols':\n",
        "    model_name = 'cvt'\n",
        "    checkpoint_path = \"serab-byols/checkpoints/cvt_s1-d1-e64_s2-d1-e256_s3-d1-e512_BYOLAs64x96-osandbyolaloss6373-e100-bs256-lr0003-rs42.pth\"\n",
        "    model = serab_byols.load_model(checkpoint_path, model_name)\n",
        "  elif model_name=='compare':\n",
        "    model = opensmile.Smile(\n",
        "        feature_set=opensmile.FeatureSet.ComParE_2016,\n",
        "        feature_level=opensmile.FeatureLevel.Functionals,\n",
        "    )\n",
        "  elif model_name=='egemaps':\n",
        "    model = opensmile.Smile(\n",
        "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "        feature_level=opensmile.FeatureLevel.Functionals,\n",
        "    )\n",
        "  return model\n",
        "\n",
        "\n",
        "def audio_embeddings(audio_list, model_name, model, sampling_rate=16000):\n",
        "  '''\n",
        "  Loads and resamples audio files \n",
        "  \n",
        "  Parameters\n",
        "  ------------\n",
        "  audio_list: list of arrays\n",
        "      A list of arrays, one array for each audio file\n",
        "  model_name: string\n",
        "      The model to used, could be 'wav2vec', 'hubert' or 'hybrid_byols'\n",
        "  model: object\n",
        "      The model generated by audio_embeddings_model function\n",
        "  n_feats: int\n",
        "      The number of features of each audio file, 6373 for 'compare' and 88 for 'egemaps'\n",
        "\n",
        "  Returns\n",
        "  ------------\n",
        "  embeddings_array: torch array\n",
        "      The array containg embeddings of all audio_files, dimension (number of audio files × n_feats)\n",
        "      \n",
        "  '''\n",
        "  if model_name=='hybrid_byols':\n",
        "    embeddings_array = serab_byols.get_scene_embeddings(audio_list, model)\n",
        "  else:\n",
        "    embeddings_list = []\n",
        "    for i in tqdm(range(len(audio_list))):\n",
        "      if model_name=='wav2vec2' or model_name=='hubert':\n",
        "        embeddings = model(audio_list[i].reshape(1,-1)).last_hidden_state.mean(1)\n",
        "        embeddings_list.append(embeddings[0])\n",
        "      elif model_name=='compare' or model_name=='egemaps':\n",
        "        embeddings = model.process_signal(audio_list[i], sampling_rate)\n",
        "        embeddings_list.append(torch.tensor(embeddings.values[0], dtype=torch.float32))\n",
        "    embeddings_array = torch.stack(embeddings_list)\n",
        "  return embeddings_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgIMNm01HGyZ"
      },
      "source": [
        "# Phase 3 Functions: Downstream Task - Speech Emotion Recognotion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91OM9gcMHWLN"
      },
      "source": [
        "## Speaker normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlFL7hMDwiqk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def speaker_normalisation(embeddings_array, speakers):\n",
        "  '''\n",
        "  Normalises embeddings_array for each speaker\n",
        "  \n",
        "  Parameters\n",
        "  ------------\n",
        "  embeddings_array: torch tensor\n",
        "      The tensor of embeddings, one row for each audio file\n",
        "  speakers: list of integers\n",
        "      The list of speakers\n",
        "\n",
        "  Returns\n",
        "  ------------\n",
        "  embeddings_array: torch tensor\n",
        "      The tensor containg normalised embeddings \n",
        "      \n",
        "  '''\n",
        "  speaker_ids = set(speakers)\n",
        "  for speaker_id in speaker_ids:\n",
        "    speaker_embeddings_indices = np.where(np.array(speakers)==speaker_id)[0]\n",
        "    speaker_embeddings = embeddings_array[speaker_embeddings_indices,:]\n",
        "    normalised_speaker_embeddings = scaler.fit_transform(speaker_embeddings)\n",
        "    embeddings_array[speaker_embeddings_indices] = torch.tensor(normalised_speaker_embeddings).float()\n",
        "  return embeddings_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of_JsmJIX34u"
      },
      "source": [
        "## Dividing into Training and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP4XPE0TS42u"
      },
      "outputs": [],
      "source": [
        "def split_train_test(normalised_embeddings_array, labels, speakers, test_size = 0.30):\n",
        "  '''\n",
        "  Splits into training and testing set with different speakers\n",
        "  \n",
        "  Parameters\n",
        "  ------------\n",
        "  normalised_embeddings_array: torch tensor\n",
        "      The tensor containing normalised embeddings \n",
        "  labels: list of strings\n",
        "      The list of emotions corresponding to audio files\n",
        "  speakers: list of integers \n",
        "      The list of speakers\n",
        "\n",
        "  Returns\n",
        "  ------------\n",
        "  X_train: torch tensor\n",
        "    The normalised embeddings that will be used for training\n",
        "  X_test: torch tensor\n",
        "    The normalised embeddings that will be used for testing\n",
        "  y_train: list of strings\n",
        "    The labels that will be used for training\n",
        "  y_test: list of strings\n",
        "    The labels that will be used for testing\n",
        "  '''\n",
        "\n",
        "  # 10 speakers in this dataset\n",
        "  all_speakers = set(speakers)\n",
        "  # 3 of the 10 total speakers\n",
        "  test_speakers = sample(all_speakers, int(test_size*len(all_speakers)))\n",
        "\n",
        "  test_speakers_indices = []\n",
        "  train_speakers_indices = []\n",
        "\n",
        "  for speaker in all_speakers:\n",
        "    if speaker in test_speakers:\n",
        "      speaker_indices = np.where(np.array(speakers)==speaker)[0]\n",
        "      test_speakers_indices.extend(speaker_indices)\n",
        "    else:\n",
        "      speaker_indices = np.where(np.array(speakers)==speaker)[0]\n",
        "      train_speakers_indices.extend(speaker_indices)\n",
        "\n",
        "  X_train = normalised_embeddings_array[train_speakers_indices]\n",
        "  X_test = normalised_embeddings_array[test_speakers_indices]\n",
        "\n",
        "  y_train = [0 for i in range(len(train_speakers_indices))]\n",
        "  y_test = [0 for i in range(len(test_speakers_indices))]\n",
        "\n",
        "  for i,index in enumerate(train_speakers_indices):\n",
        "    y_train[i] = labels[index]\n",
        "  for i,index in enumerate(test_speakers_indices):\n",
        "    y_test[i] = labels[index]\n",
        "\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q5gqY6Zv7tF"
      },
      "source": [
        "# EmoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yibhy17jDoPL"
      },
      "source": [
        "# Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Jncl071Q_z",
        "outputId": "ffb22e22-cd2d-403e-ac55-711b8aa7aa1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading berlin-database-of-emotional-speech-emodb.zip to /content\n",
            " 87% 33.0M/38.0M [00:00<00:00, 121MB/s] \n",
            "100% 38.0M/38.0M [00:00<00:00, 126MB/s]\n",
            "Archive:  berlin-database-of-emotional-speech-emodb.zip\n",
            "  inflating: wav/03a01Fa.wav         \n",
            "  inflating: wav/03a01Nc.wav         \n",
            "  inflating: wav/03a01Wa.wav         \n",
            "  inflating: wav/03a02Fc.wav         \n",
            "  inflating: wav/03a02Nc.wav         \n",
            "  inflating: wav/03a02Ta.wav         \n",
            "  inflating: wav/03a02Wb.wav         \n",
            "  inflating: wav/03a02Wc.wav         \n",
            "  inflating: wav/03a04Ad.wav         \n",
            "  inflating: wav/03a04Fd.wav         \n",
            "  inflating: wav/03a04Lc.wav         \n",
            "  inflating: wav/03a04Nc.wav         \n",
            "  inflating: wav/03a04Ta.wav         \n",
            "  inflating: wav/03a04Wc.wav         \n",
            "  inflating: wav/03a05Aa.wav         \n",
            "  inflating: wav/03a05Fc.wav         \n",
            "  inflating: wav/03a05Nd.wav         \n",
            "  inflating: wav/03a05Tc.wav         \n",
            "  inflating: wav/03a05Wa.wav         \n",
            "  inflating: wav/03a05Wb.wav         \n",
            "  inflating: wav/03a07Fa.wav         \n",
            "  inflating: wav/03a07Fb.wav         \n",
            "  inflating: wav/03a07La.wav         \n",
            "  inflating: wav/03a07Nc.wav         \n",
            "  inflating: wav/03a07Wc.wav         \n",
            "  inflating: wav/03b01Fa.wav         \n",
            "  inflating: wav/03b01Lb.wav         \n",
            "  inflating: wav/03b01Nb.wav         \n",
            "  inflating: wav/03b01Td.wav         \n",
            "  inflating: wav/03b01Wa.wav         \n",
            "  inflating: wav/03b01Wc.wav         \n",
            "  inflating: wav/03b02Aa.wav         \n",
            "  inflating: wav/03b02La.wav         \n",
            "  inflating: wav/03b02Na.wav         \n",
            "  inflating: wav/03b02Tb.wav         \n",
            "  inflating: wav/03b02Wb.wav         \n",
            "  inflating: wav/03b03Nb.wav         \n",
            "  inflating: wav/03b03Tc.wav         \n",
            "  inflating: wav/03b03Wc.wav         \n",
            "  inflating: wav/03b09La.wav         \n",
            "  inflating: wav/03b09Nc.wav         \n",
            "  inflating: wav/03b09Tc.wav         \n",
            "  inflating: wav/03b09Wa.wav         \n",
            "  inflating: wav/03b10Ab.wav         \n",
            "  inflating: wav/03b10Ec.wav         \n",
            "  inflating: wav/03b10Na.wav         \n",
            "  inflating: wav/03b10Nc.wav         \n",
            "  inflating: wav/03b10Wb.wav         \n",
            "  inflating: wav/03b10Wc.wav         \n",
            "  inflating: wav/08a01Ab.wav         \n",
            "  inflating: wav/08a01Fd.wav         \n",
            "  inflating: wav/08a01Lc.wav         \n",
            "  inflating: wav/08a01Na.wav         \n",
            "  inflating: wav/08a01Wa.wav         \n",
            "  inflating: wav/08a01Wc.wav         \n",
            "  inflating: wav/08a02Ab.wav         \n",
            "  inflating: wav/08a02Ac.wav         \n",
            "  inflating: wav/08a02Fe.wav         \n",
            "  inflating: wav/08a02La.wav         \n",
            "  inflating: wav/08a02Na.wav         \n",
            "  inflating: wav/08a02Tb.wav         \n",
            "  inflating: wav/08a02Wc.wav         \n",
            "  inflating: wav/08a04Ff.wav         \n",
            "  inflating: wav/08a04La.wav         \n",
            "  inflating: wav/08a04Nc.wav         \n",
            "  inflating: wav/08a04Tb.wav         \n",
            "  inflating: wav/08a04Wc.wav         \n",
            "  inflating: wav/08a05Fe.wav         \n",
            "  inflating: wav/08a05Lc.wav         \n",
            "  inflating: wav/08a05Nb.wav         \n",
            "  inflating: wav/08a05Ta.wav         \n",
            "  inflating: wav/08a05Wa.wav         \n",
            "  inflating: wav/08a07Fd.wav         \n",
            "  inflating: wav/08a07La.wav         \n",
            "  inflating: wav/08a07Na.wav         \n",
            "  inflating: wav/08a07Ta.wav         \n",
            "  inflating: wav/08a07Tb.wav         \n",
            "  inflating: wav/08a07Wc.wav         \n",
            "  inflating: wav/08b01Aa.wav         \n",
            "  inflating: wav/08b01Fd.wav         \n",
            "  inflating: wav/08b01Fe.wav         \n",
            "  inflating: wav/08b01Lb.wav         \n",
            "  inflating: wav/08b01Na.wav         \n",
            "  inflating: wav/08b01Wa.wav         \n",
            "  inflating: wav/08b02Ff.wav         \n",
            "  inflating: wav/08b02La.wav         \n",
            "  inflating: wav/08b02Nb.wav         \n",
            "  inflating: wav/08b02Tc.wav         \n",
            "  inflating: wav/08b02Wd.wav         \n",
            "  inflating: wav/08b03Fe.wav         \n",
            "  inflating: wav/08b03Lc.wav         \n",
            "  inflating: wav/08b03Nb.wav         \n",
            "  inflating: wav/08b03Tc.wav         \n",
            "  inflating: wav/08b03Wd.wav         \n",
            "  inflating: wav/08b09Ab.wav         \n",
            "  inflating: wav/08b09Fd.wav         \n",
            "  inflating: wav/08b09Lc.wav         \n",
            "  inflating: wav/08b09Nb.wav         \n",
            "  inflating: wav/08b09Tb.wav         \n",
            "  inflating: wav/08b09Wa.wav         \n",
            "  inflating: wav/08b09Wc.wav         \n",
            "  inflating: wav/08b10Aa.wav         \n",
            "  inflating: wav/08b10Fd.wav         \n",
            "  inflating: wav/08b10La.wav         \n",
            "  inflating: wav/08b10Nc.wav         \n",
            "  inflating: wav/08b10Tc.wav         \n",
            "  inflating: wav/08b10Wa.wav         \n",
            "  inflating: wav/09a01Ea.wav         \n",
            "  inflating: wav/09a01Fa.wav         \n",
            "  inflating: wav/09a01Nb.wav         \n",
            "  inflating: wav/09a01Wb.wav         \n",
            "  inflating: wav/09a02Ea.wav         \n",
            "  inflating: wav/09a02Eb.wav         \n",
            "  inflating: wav/09a02La.wav         \n",
            "  inflating: wav/09a02Wb.wav         \n",
            "  inflating: wav/09a04Fd.wav         \n",
            "  inflating: wav/09a04La.wav         \n",
            "  inflating: wav/09a04Nb.wav         \n",
            "  inflating: wav/09a04Wa.wav         \n",
            "  inflating: wav/09a05Ed.wav         \n",
            "  inflating: wav/09a05Lc.wav         \n",
            "  inflating: wav/09a05Nb.wav         \n",
            "  inflating: wav/09a05Tb.wav         \n",
            "  inflating: wav/09a05Wb.wav         \n",
            "  inflating: wav/09a05Wc.wav         \n",
            "  inflating: wav/09a07Eb.wav         \n",
            "  inflating: wav/09a07Na.wav         \n",
            "  inflating: wav/09a07Ta.wav         \n",
            "  inflating: wav/09a07Wb.wav         \n",
            "  inflating: wav/09a07Wd.wav         \n",
            "  inflating: wav/09b01Ea.wav         \n",
            "  inflating: wav/09b01Na.wav         \n",
            "  inflating: wav/09b01Wb.wav         \n",
            "  inflating: wav/09b02Na.wav         \n",
            "  inflating: wav/09b02Tb.wav         \n",
            "  inflating: wav/09b02Wc.wav         \n",
            "  inflating: wav/09b02Wd.wav         \n",
            "  inflating: wav/09b03Ed.wav         \n",
            "  inflating: wav/09b03Fa.wav         \n",
            "  inflating: wav/09b03Fd.wav         \n",
            "  inflating: wav/09b03Lb.wav         \n",
            "  inflating: wav/09b03Nb.wav         \n",
            "  inflating: wav/09b03Ta.wav         \n",
            "  inflating: wav/09b03Wb.wav         \n",
            "  inflating: wav/09b09Ea.wav         \n",
            "  inflating: wav/09b09Nd.wav         \n",
            "  inflating: wav/09b09Wa.wav         \n",
            "  inflating: wav/09b10Aa.wav         \n",
            "  inflating: wav/09b10Nd.wav         \n",
            "  inflating: wav/09b10Wa.wav         \n",
            "  inflating: wav/10a01Ac.wav         \n",
            "  inflating: wav/10a01Nb.wav         \n",
            "  inflating: wav/10a01Wa.wav         \n",
            "  inflating: wav/10a02Ab.wav         \n",
            "  inflating: wav/10a02Fa.wav         \n",
            "  inflating: wav/10a02Lb.wav         \n",
            "  inflating: wav/10a02Na.wav         \n",
            "  inflating: wav/10a02Wa.wav         \n",
            "  inflating: wav/10a04Fd.wav         \n",
            "  inflating: wav/10a04Nb.wav         \n",
            "  inflating: wav/10a04Wa.wav         \n",
            "  inflating: wav/10a04Wb.wav         \n",
            "  inflating: wav/10a05Aa.wav         \n",
            "  inflating: wav/10a05Ld.wav         \n",
            "  inflating: wav/10a05Tb.wav         \n",
            "  inflating: wav/10a05Wb.wav         \n",
            "  inflating: wav/10a07Aa.wav         \n",
            "  inflating: wav/10a07Ad.wav         \n",
            "  inflating: wav/10a07La.wav         \n",
            "  inflating: wav/10a07Ta.wav         \n",
            "  inflating: wav/10a07Wb.wav         \n",
            "  inflating: wav/10b01Aa.wav         \n",
            "  inflating: wav/10b01Ea.wav         \n",
            "  inflating: wav/10b01Fa.wav         \n",
            "  inflating: wav/10b01Lb.wav         \n",
            "  inflating: wav/10b02Aa.wav         \n",
            "  inflating: wav/10b02La.wav         \n",
            "  inflating: wav/10b02Na.wav         \n",
            "  inflating: wav/10b02Wb.wav         \n",
            "  inflating: wav/10b03La.wav         \n",
            "  inflating: wav/10b03Tb.wav         \n",
            "  inflating: wav/10b03Wb.wav         \n",
            "  inflating: wav/10b09Ad.wav         \n",
            "  inflating: wav/10b09Lb.wav         \n",
            "  inflating: wav/10b09Wb.wav         \n",
            "  inflating: wav/10b10Fc.wav         \n",
            "  inflating: wav/10b10Lc.wav         \n",
            "  inflating: wav/10b10Wa.wav         \n",
            "  inflating: wav/11a01Aa.wav         \n",
            "  inflating: wav/11a01Ab.wav         \n",
            "  inflating: wav/11a01Ld.wav         \n",
            "  inflating: wav/11a01Nd.wav         \n",
            "  inflating: wav/11a01Wc.wav         \n",
            "  inflating: wav/11a02Ec.wav         \n",
            "  inflating: wav/11a02Fb.wav         \n",
            "  inflating: wav/11a02Ld.wav         \n",
            "  inflating: wav/11a02Nc.wav         \n",
            "  inflating: wav/11a02Tc.wav         \n",
            "  inflating: wav/11a02Wc.wav         \n",
            "  inflating: wav/11a04Ac.wav         \n",
            "  inflating: wav/11a04Fd.wav         \n",
            "  inflating: wav/11a04Nd.wav         \n",
            "  inflating: wav/11a04Wc.wav         \n",
            "  inflating: wav/11a05Ad.wav         \n",
            "  inflating: wav/11a05Fb.wav         \n",
            "  inflating: wav/11a05Fc.wav         \n",
            "  inflating: wav/11a05Lc.wav         \n",
            "  inflating: wav/11a05Na.wav         \n",
            "  inflating: wav/11a05Td.wav         \n",
            "  inflating: wav/11a05Wd.wav         \n",
            "  inflating: wav/11a07Ac.wav         \n",
            "  inflating: wav/11a07Ld.wav         \n",
            "  inflating: wav/11a07Ta.wav         \n",
            "  inflating: wav/11a07Wc.wav         \n",
            "  inflating: wav/11b01Ab.wav         \n",
            "  inflating: wav/11b01Eb.wav         \n",
            "  inflating: wav/11b01Fc.wav         \n",
            "  inflating: wav/11b01Lb.wav         \n",
            "  inflating: wav/11b01Nc.wav         \n",
            "  inflating: wav/11b01Wd.wav         \n",
            "  inflating: wav/11b02Ab.wav         \n",
            "  inflating: wav/11b02Fd.wav         \n",
            "  inflating: wav/11b02Na.wav         \n",
            "  inflating: wav/11b02Td.wav         \n",
            "  inflating: wav/11b02Wb.wav         \n",
            "  inflating: wav/11b03Fc.wav         \n",
            "  inflating: wav/11b03Lc.wav         \n",
            "  inflating: wav/11b03Nb.wav         \n",
            "  inflating: wav/11b03Td.wav         \n",
            "  inflating: wav/11b03Wa.wav         \n",
            "  inflating: wav/11b03Wb.wav         \n",
            "  inflating: wav/11b09Ad.wav         \n",
            "  inflating: wav/11b09Fd.wav         \n",
            "  inflating: wav/11b09Ld.wav         \n",
            "  inflating: wav/11b09Na.wav         \n",
            "  inflating: wav/11b09Td.wav         \n",
            "  inflating: wav/11b09Wa.wav         \n",
            "  inflating: wav/11b10Ad.wav         \n",
            "  inflating: wav/11b10Ae.wav         \n",
            "  inflating: wav/11b10Ld.wav         \n",
            "  inflating: wav/11b10Nc.wav         \n",
            "  inflating: wav/11b10Td.wav         \n",
            "  inflating: wav/11b10Wa.wav         \n",
            "  inflating: wav/12a01Fb.wav         \n",
            "  inflating: wav/12a01Lb.wav         \n",
            "  inflating: wav/12a01Nb.wav         \n",
            "  inflating: wav/12a01Wc.wav         \n",
            "  inflating: wav/12a02Ac.wav         \n",
            "  inflating: wav/12a02Ec.wav         \n",
            "  inflating: wav/12a02Nb.wav         \n",
            "  inflating: wav/12a02Wa.wav         \n",
            "  inflating: wav/12a02Wc.wav         \n",
            "  inflating: wav/12a04Wc.wav         \n",
            "  inflating: wav/12a05Ab.wav         \n",
            "  inflating: wav/12a05Lb.wav         \n",
            "  inflating: wav/12a05Nd.wav         \n",
            "  inflating: wav/12a05Ta.wav         \n",
            "  inflating: wav/12a05Wb.wav         \n",
            "  inflating: wav/12a07Ac.wav         \n",
            "  inflating: wav/12a07La.wav         \n",
            "  inflating: wav/12a07Wa.wav         \n",
            "  inflating: wav/12b01Ta.wav         \n",
            "  inflating: wav/12b01Wa.wav         \n",
            "  inflating: wav/12b02Ad.wav         \n",
            "  inflating: wav/12b02Ea.wav         \n",
            "  inflating: wav/12b02Fb.wav         \n",
            "  inflating: wav/12b02Na.wav         \n",
            "  inflating: wav/12b02Wa.wav         \n",
            "  inflating: wav/12b02Wb.wav         \n",
            "  inflating: wav/12b02Wd.wav         \n",
            "  inflating: wav/12b03La.wav         \n",
            "  inflating: wav/12b03Ta.wav         \n",
            "  inflating: wav/12b09Ac.wav         \n",
            "  inflating: wav/12b09Td.wav         \n",
            "  inflating: wav/12b09Wc.wav         \n",
            "  inflating: wav/12b10Ac.wav         \n",
            "  inflating: wav/12b10Ld.wav         \n",
            "  inflating: wav/12b10Wa.wav         \n",
            "  inflating: wav/13a01Ac.wav         \n",
            "  inflating: wav/13a01Ea.wav         \n",
            "  inflating: wav/13a01Ec.wav         \n",
            "  inflating: wav/13a01Fd.wav         \n",
            "  inflating: wav/13a01Lb.wav         \n",
            "  inflating: wav/13a01Nb.wav         \n",
            "  inflating: wav/13a01Wb.wav         \n",
            "  inflating: wav/13a02Ad.wav         \n",
            "  inflating: wav/13a02Ec.wav         \n",
            "  inflating: wav/13a02Fa.wav         \n",
            "  inflating: wav/13a02Lc.wav         \n",
            "  inflating: wav/13a02Nc.wav         \n",
            "  inflating: wav/13a02Ta.wav         \n",
            "  inflating: wav/13a02Wa.wav         \n",
            "  inflating: wav/13a04Ac.wav         \n",
            "  inflating: wav/13a04Fc.wav         \n",
            "  inflating: wav/13a04Lb.wav         \n",
            "  inflating: wav/13a04Ta.wav         \n",
            "  inflating: wav/13a04Wc.wav         \n",
            "  inflating: wav/13a05Aa.wav         \n",
            "  inflating: wav/13a05Ea.wav         \n",
            "  inflating: wav/13a05Lc.wav         \n",
            "  inflating: wav/13a05Nb.wav         \n",
            "  inflating: wav/13a05Tc.wav         \n",
            "  inflating: wav/13a05Wa.wav         \n",
            "  inflating: wav/13a05Wc.wav         \n",
            "  inflating: wav/13a07Fd.wav         \n",
            "  inflating: wav/13a07Lb.wav         \n",
            "  inflating: wav/13a07Na.wav         \n",
            "  inflating: wav/13a07Tc.wav         \n",
            "  inflating: wav/13a07Wb.wav         \n",
            "  inflating: wav/13b01Ab.wav         \n",
            "  inflating: wav/13b01Ec.wav         \n",
            "  inflating: wav/13b01Fc.wav         \n",
            "  inflating: wav/13b01Ld.wav         \n",
            "  inflating: wav/13b01Nc.wav         \n",
            "  inflating: wav/13b01Wa.wav         \n",
            "  inflating: wav/13b02Fb.wav         \n",
            "  inflating: wav/13b02Lc.wav         \n",
            "  inflating: wav/13b02Nb.wav         \n",
            "  inflating: wav/13b02Wa.wav         \n",
            "  inflating: wav/13b03Ac.wav         \n",
            "  inflating: wav/13b03Ed.wav         \n",
            "  inflating: wav/13b03Fd.wav         \n",
            "  inflating: wav/13b03Lb.wav         \n",
            "  inflating: wav/13b03Na.wav         \n",
            "  inflating: wav/13b03Td.wav         \n",
            "  inflating: wav/13b03Wc.wav         \n",
            "  inflating: wav/13b09Ab.wav         \n",
            "  inflating: wav/13b09Ec.wav         \n",
            "  inflating: wav/13b09Fb.wav         \n",
            "  inflating: wav/13b09Fc.wav         \n",
            "  inflating: wav/13b09La.wav         \n",
            "  inflating: wav/13b09Na.wav         \n",
            "  inflating: wav/13b09Wa.wav         \n",
            "  inflating: wav/13b10Ec.wav         \n",
            "  inflating: wav/13b10Fa.wav         \n",
            "  inflating: wav/13b10La.wav         \n",
            "  inflating: wav/13b10Nc.wav         \n",
            "  inflating: wav/13b10Wa.wav         \n",
            "  inflating: wav/13b10Wc.wav         \n",
            "  inflating: wav/14a01Aa.wav         \n",
            "  inflating: wav/14a01Ac.wav         \n",
            "  inflating: wav/14a01Ea.wav         \n",
            "  inflating: wav/14a01Na.wav         \n",
            "  inflating: wav/14a01Wa.wav         \n",
            "  inflating: wav/14a01Wc.wav         \n",
            "  inflating: wav/14a02Ab.wav         \n",
            "  inflating: wav/14a02Ea.wav         \n",
            "  inflating: wav/14a02Fd.wav         \n",
            "  inflating: wav/14a02La.wav         \n",
            "  inflating: wav/14a02Nc.wav         \n",
            "  inflating: wav/14a02Tb.wav         \n",
            "  inflating: wav/14a02Wa.wav         \n",
            "  inflating: wav/14a02Wc.wav         \n",
            "  inflating: wav/14a04Aa.wav         \n",
            "  inflating: wav/14a04Ed.wav         \n",
            "  inflating: wav/14a04Lb.wav         \n",
            "  inflating: wav/14a04Tb.wav         \n",
            "  inflating: wav/14a04Tc.wav         \n",
            "  inflating: wav/14a04Wb.wav         \n",
            "  inflating: wav/14a04Wc.wav         \n",
            "  inflating: wav/14a05Aa.wav         \n",
            "  inflating: wav/14a05Ac.wav         \n",
            "  inflating: wav/14a05Fa.wav         \n",
            "  inflating: wav/14a05Fb.wav         \n",
            "  inflating: wav/14a05Lb.wav         \n",
            "  inflating: wav/14a05Na.wav         \n",
            "  inflating: wav/14a05Ta.wav         \n",
            "  inflating: wav/14a05Tc.wav         \n",
            "  inflating: wav/14a05Wa.wav         \n",
            "  inflating: wav/14a05Wb.wav         \n",
            "  inflating: wav/14a07Aa.wav         \n",
            "  inflating: wav/14a07Eb.wav         \n",
            "  inflating: wav/14a07Fd.wav         \n",
            "  inflating: wav/14a07Lc.wav         \n",
            "  inflating: wav/14a07Ld.wav         \n",
            "  inflating: wav/14a07Na.wav         \n",
            "  inflating: wav/14a07Tc.wav         \n",
            "  inflating: wav/14a07Wc.wav         \n",
            "  inflating: wav/14b01Ac.wav         \n",
            "  inflating: wav/14b01Eb.wav         \n",
            "  inflating: wav/14b01Fa.wav         \n",
            "  inflating: wav/14b01Fc.wav         \n",
            "  inflating: wav/14b01Na.wav         \n",
            "  inflating: wav/14b01Wc.wav         \n",
            "  inflating: wav/14b02Aa.wav         \n",
            "  inflating: wav/14b02Fb.wav         \n",
            "  inflating: wav/14b02Na.wav         \n",
            "  inflating: wav/14b02Tc.wav         \n",
            "  inflating: wav/14b02Wb.wav         \n",
            "  inflating: wav/14b02Wd.wav         \n",
            "  inflating: wav/14b03Ad.wav         \n",
            "  inflating: wav/14b03Ed.wav         \n",
            "  inflating: wav/14b03Lb.wav         \n",
            "  inflating: wav/14b03Ta.wav         \n",
            "  inflating: wav/14b03Wb.wav         \n",
            "  inflating: wav/14b09Ac.wav         \n",
            "  inflating: wav/14b09Ea.wav         \n",
            "  inflating: wav/14b09Fc.wav         \n",
            "  inflating: wav/14b09Lb.wav         \n",
            "  inflating: wav/14b09Td.wav         \n",
            "  inflating: wav/14b09Wa.wav         \n",
            "  inflating: wav/14b09Wc.wav         \n",
            "  inflating: wav/14b10Ad.wav         \n",
            "  inflating: wav/14b10Eb.wav         \n",
            "  inflating: wav/14b10Lb.wav         \n",
            "  inflating: wav/14b10Nb.wav         \n",
            "  inflating: wav/14b10Tc.wav         \n",
            "  inflating: wav/14b10Wc.wav         \n",
            "  inflating: wav/15a01Ea.wav         \n",
            "  inflating: wav/15a01Fb.wav         \n",
            "  inflating: wav/15a01La.wav         \n",
            "  inflating: wav/15a01Nb.wav         \n",
            "  inflating: wav/15a01Wa.wav         \n",
            "  inflating: wav/15a02Ac.wav         \n",
            "  inflating: wav/15a02Ea.wav         \n",
            "  inflating: wav/15a02La.wav         \n",
            "  inflating: wav/15a02Na.wav         \n",
            "  inflating: wav/15a02Ta.wav         \n",
            "  inflating: wav/15a02Wb.wav         \n",
            "  inflating: wav/15a02Wd.wav         \n",
            "  inflating: wav/15a04Ab.wav         \n",
            "  inflating: wav/15a04Ac.wav         \n",
            "  inflating: wav/15a04Fd.wav         \n",
            "  inflating: wav/15a04Nc.wav         \n",
            "  inflating: wav/15a04Wa.wav         \n",
            "  inflating: wav/15a04Wb.wav         \n",
            "  inflating: wav/15a05Eb.wav         \n",
            "  inflating: wav/15a05Fb.wav         \n",
            "  inflating: wav/15a05Lb.wav         \n",
            "  inflating: wav/15a05Na.wav         \n",
            "  inflating: wav/15a05Wa.wav         \n",
            "  inflating: wav/15a07Ac.wav         \n",
            "  inflating: wav/15a07Eb.wav         \n",
            "  inflating: wav/15a07Fa.wav         \n",
            "  inflating: wav/15a07Fb.wav         \n",
            "  inflating: wav/15a07Ld.wav         \n",
            "  inflating: wav/15a07Nc.wav         \n",
            "  inflating: wav/15b01Ec.wav         \n",
            "  inflating: wav/15b01Lb.wav         \n",
            "  inflating: wav/15b01Na.wav         \n",
            "  inflating: wav/15b01Wc.wav         \n",
            "  inflating: wav/15b02Aa.wav         \n",
            "  inflating: wav/15b02Lb.wav         \n",
            "  inflating: wav/15b02Nd.wav         \n",
            "  inflating: wav/15b02Tc.wav         \n",
            "  inflating: wav/15b02Wa.wav         \n",
            "  inflating: wav/15b02Wc.wav         \n",
            "  inflating: wav/15b03Aa.wav         \n",
            "  inflating: wav/15b03Lc.wav         \n",
            "  inflating: wav/15b03Nb.wav         \n",
            "  inflating: wav/15b03Tc.wav         \n",
            "  inflating: wav/15b03Wa.wav         \n",
            "  inflating: wav/15b03Wb.wav         \n",
            "  inflating: wav/15b09Ac.wav         \n",
            "  inflating: wav/15b09Fa.wav         \n",
            "  inflating: wav/15b09La.wav         \n",
            "  inflating: wav/15b09Nb.wav         \n",
            "  inflating: wav/15b09Ta.wav         \n",
            "  inflating: wav/15b09Wb.wav         \n",
            "  inflating: wav/15b10Ac.wav         \n",
            "  inflating: wav/15b10Lc.wav         \n",
            "  inflating: wav/15b10Nb.wav         \n",
            "  inflating: wav/15b10Nc.wav         \n",
            "  inflating: wav/15b10Wa.wav         \n",
            "  inflating: wav/16a01Ec.wav         \n",
            "  inflating: wav/16a01Fc.wav         \n",
            "  inflating: wav/16a01Lb.wav         \n",
            "  inflating: wav/16a01Nc.wav         \n",
            "  inflating: wav/16a01Tb.wav         \n",
            "  inflating: wav/16a01Wb.wav         \n",
            "  inflating: wav/16a02Ea.wav         \n",
            "  inflating: wav/16a02Ec.wav         \n",
            "  inflating: wav/16a02Lb.wav         \n",
            "  inflating: wav/16a02Nb.wav         \n",
            "  inflating: wav/16a02Tc.wav         \n",
            "  inflating: wav/16a02Wb.wav         \n",
            "  inflating: wav/16a04Ab.wav         \n",
            "  inflating: wav/16a04Ea.wav         \n",
            "  inflating: wav/16a04Fa.wav         \n",
            "  inflating: wav/16a04La.wav         \n",
            "  inflating: wav/16a04Lc.wav         \n",
            "  inflating: wav/16a04Nc.wav         \n",
            "  inflating: wav/16a04Tc.wav         \n",
            "  inflating: wav/16a04Wb.wav         \n",
            "  inflating: wav/16a04Wc.wav         \n",
            "  inflating: wav/16a05Ab.wav         \n",
            "  inflating: wav/16a05Ea.wav         \n",
            "  inflating: wav/16a05Fc.wav         \n",
            "  inflating: wav/16a05La.wav         \n",
            "  inflating: wav/16a05Tb.wav         \n",
            "  inflating: wav/16a05Wb.wav         \n",
            "  inflating: wav/16a05Wc.wav         \n",
            "  inflating: wav/16a07Ea.wav         \n",
            "  inflating: wav/16a07Fa.wav         \n",
            "  inflating: wav/16a07Fb.wav         \n",
            "  inflating: wav/16a07La.wav         \n",
            "  inflating: wav/16a07Lb.wav         \n",
            "  inflating: wav/16a07Nb.wav         \n",
            "  inflating: wav/16a07Td.wav         \n",
            "  inflating: wav/16a07Wa.wav         \n",
            "  inflating: wav/16b01Aa.wav         \n",
            "  inflating: wav/16b01Eb.wav         \n",
            "  inflating: wav/16b01Fa.wav         \n",
            "  inflating: wav/16b01La.wav         \n",
            "  inflating: wav/16b01Lc.wav         \n",
            "  inflating: wav/16b01Tb.wav         \n",
            "  inflating: wav/16b01Wa.wav         \n",
            "  inflating: wav/16b01Wb.wav         \n",
            "  inflating: wav/16b02Aa.wav         \n",
            "  inflating: wav/16b02Eb.wav         \n",
            "  inflating: wav/16b02Fd.wav         \n",
            "  inflating: wav/16b02Lb.wav         \n",
            "  inflating: wav/16b02Wb.wav         \n",
            "  inflating: wav/16b03Ad.wav         \n",
            "  inflating: wav/16b03Ea.wav         \n",
            "  inflating: wav/16b03Fa.wav         \n",
            "  inflating: wav/16b03Fd.wav         \n",
            "  inflating: wav/16b03La.wav         \n",
            "  inflating: wav/16b03Nb.wav         \n",
            "  inflating: wav/16b03Ta.wav         \n",
            "  inflating: wav/16b03Wb.wav         \n",
            "  inflating: wav/16b09Ab.wav         \n",
            "  inflating: wav/16b09Eb.wav         \n",
            "  inflating: wav/16b09Fb.wav         \n",
            "  inflating: wav/16b09La.wav         \n",
            "  inflating: wav/16b09Lb.wav         \n",
            "  inflating: wav/16b09Wb.wav         \n",
            "  inflating: wav/16b10Aa.wav         \n",
            "  inflating: wav/16b10Eb.wav         \n",
            "  inflating: wav/16b10Fb.wav         \n",
            "  inflating: wav/16b10Lb.wav         \n",
            "  inflating: wav/16b10Tb.wav         \n",
            "  inflating: wav/16b10Td.wav         \n",
            "  inflating: wav/16b10Wa.wav         \n",
            "  inflating: wav/16b10Wb.wav         \n",
            "\n",
            "number of audio files: 535\n",
            "torch.Size([28232])\n"
          ]
        }
      ],
      "source": [
        "# Phase_1\n",
        "# Load dataset\n",
        "! kaggle datasets download -d piyushagni5/berlin-database-of-emotional-speech-emodb\n",
        "! unzip berlin-database-of-emotional-speech-emodb.zip\n",
        "\n",
        "# Resample dataset\n",
        "audio_files_emo = glob(os.path.join('/content/wav','*.wav'))\n",
        "audio_list_emo= load_audio_files(audio_files_emo, resampling_frequency=16000)\n",
        "\n",
        "\n",
        "# Verify phase_1\n",
        "print()\n",
        "print('number of audio files: {}'.format(len(audio_list_emo)))\n",
        "print(audio_list_emo[0].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTaOghCkDlq9"
      },
      "source": [
        "# Phase 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvmZ0RwTDXCY",
        "outputId": "43bc87c6-2b67-4565-e5d5-ae9c91dc4dbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating Embeddings...: 100%|██████████| 535/535 [00:32<00:00, 16.29it/s]\n",
            "100%|██████████| 535/535 [01:03<00:00,  8.43it/s]\n",
            "100%|██████████| 535/535 [00:59<00:00,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "MODEL: byols\n",
            "\n",
            "The shape of the embeddings array is torch.Size([535, 2048])\n",
            "The embeddings array is: \n",
            "tensor([[ 4.7838,  5.1332,  1.4826,  ...,  6.5955,  1.3091,  4.0811],\n",
            "        [ 2.1415,  4.3838, -0.1100,  ...,  4.6903,  0.9929,  4.6195],\n",
            "        [ 5.1235,  6.4362,  1.3371,  ...,  4.0452, -0.5890,  3.3637],\n",
            "        ...,\n",
            "        [ 4.6546,  3.6335,  1.4479,  ...,  4.3445,  0.4926,  3.9791],\n",
            "        [ 5.6109,  4.9422,  2.1563,  ...,  4.2048,  0.1288,  3.7671],\n",
            "        [ 5.6137,  5.7598,  0.7077,  ...,  5.4536,  0.5266,  4.1597]])\n",
            "\n",
            "\n",
            "MODEL: compare\n",
            "\n",
            "The shape of the embeddings array is torch.Size([535, 6373])\n",
            "The embeddings array is: \n",
            "tensor([[3.6113e+00, 1.3018e-01, 9.9408e-01,  ..., 7.0783e+01, 1.2688e+02,\n",
            "         6.3207e+01],\n",
            "        [3.3879e+00, 1.6026e-01, 9.9359e-01,  ..., 4.9951e+01, 1.0987e+02,\n",
            "         5.0209e+01],\n",
            "        [3.6579e+00, 1.2462e-01, 9.1185e-03,  ..., 5.8800e+01, 1.1421e+02,\n",
            "         5.7545e+01],\n",
            "        ...,\n",
            "        [3.5641e+00, 3.2704e-01, 7.0440e-01,  ..., 5.6244e+01, 1.1399e+02,\n",
            "         4.3725e+01],\n",
            "        [3.7234e+00, 6.5217e-01, 6.6890e-03,  ..., 6.7520e+01, 1.1999e+02,\n",
            "         6.1047e+01],\n",
            "        [3.4291e+00, 7.2072e-01, 5.4054e-02,  ..., 5.2421e+01, 1.2529e+02,\n",
            "         6.9579e+01]])\n",
            "\n",
            "\n",
            "MODEL: egemaps\n",
            "\n",
            "The shape of the embeddings array is torch.Size([535, 88])\n",
            "The embeddings array is: \n",
            "tensor([[ 33.1357,   0.1129,  29.9142,  ...,   0.1086,   0.0920, -17.4566],\n",
            "        [ 25.3224,   0.3001,  22.5472,  ...,   0.0856,   0.0374, -21.0918],\n",
            "        [ 30.9805,   0.2221,  27.8437,  ...,   0.1054,   0.0598, -19.1841],\n",
            "        ...,\n",
            "        [ 33.9716,   0.1024,  29.5605,  ...,   0.0783,   0.0426, -17.5533],\n",
            "        [ 36.2582,   0.1134,  32.0524,  ...,   0.0975,   0.0549, -15.3031],\n",
            "        [ 35.1474,   0.1699,  31.4157,  ...,   0.1871,   0.0861, -13.8330]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Phase_2\n",
        "\n",
        "# Wav2vec\n",
        "# model = audio_embeddings_model(model_name='wav2vec2')\n",
        "# embeddings_array_wav2vec = audio_embeddings(audio_list_emo[:50], model_name='wav2vec2', model=model)\n",
        "\n",
        "# Hubert\n",
        "# model = audio_embeddings_model(model_name='hubert')\n",
        "# embeddings_array_hubert = audio_embeddings(audio_list_emo[:50], model_name='hubert', model=model)\n",
        "\n",
        "# Hybrid BYOLS\n",
        "model = audio_embeddings_model(model_name='hybrid_byols')\n",
        "embeddings_array_byols = audio_embeddings(audio_list_emo, model_name='hybrid_byols', model=model)\n",
        "\n",
        "# EmoDB compare\n",
        "model = audio_embeddings_model(model_name='compare')\n",
        "embeddings_array_compare = audio_embeddings(audio_list_emo, model_name='compare', model=model)\n",
        "\n",
        "# EmoDB egemaps\n",
        "model = audio_embeddings_model(model_name='egemaps')\n",
        "embeddings_array_egemaps = audio_embeddings(audio_list_emo, model_name='egemaps', model=model)\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Verify Phase_2\n",
        "models = ['byols', 'compare', 'egemaps']\n",
        "embeddings_arrays = [embeddings_array_byols, embeddings_array_compare, embeddings_array_egemaps]\n",
        "\n",
        "for i in range(len(models)):\n",
        "  print()\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  print()\n",
        "  print('The shape of the embeddings array is {}'.format(embeddings_arrays[i].shape))\n",
        "  print('The embeddings array is: ')\n",
        "  print((embeddings_arrays[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJP6eGZYDiB-"
      },
      "source": [
        "# Phase 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I17090Zh3uPR"
      },
      "source": [
        "### Speaker normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uibu-ZnCDg_D",
        "outputId": "d1cee5ee-f30b-46c1-b930-52c16b612498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speakers:\n",
            "[8, 11, 9, 14, 16, 13, 13, 16, 16, 9, 9, 16, 15, 12, 9, 8, 16, 15, 15, 16, 11, 9, 12, 10, 11, 12, 11, 14, 8, 3, 9, 13, 13, 16, 16, 12, 16, 11, 16, 10, 9, 13, 15, 3, 13, 3, 9, 11, 10, 15, 15, 3, 9, 3, 9, 10, 13, 10, 8, 16, 15, 14, 15, 14, 14, 13, 14, 15, 3, 8, 14, 11, 8, 14, 11, 14, 16, 3, 11, 11, 3, 16, 14, 9, 3, 9, 9, 10, 3, 11, 13, 10, 11, 16, 13, 14, 15, 13, 14, 11, 11, 8, 15, 3, 16, 8, 13, 16, 8, 11, 3, 3, 8, 14, 9, 15, 10, 15, 3, 3, 11, 10, 13, 15, 11, 16, 9, 14, 13, 13, 16, 13, 16, 15, 10, 14, 8, 13, 16, 14, 8, 8, 12, 8, 14, 3, 11, 14, 3, 15, 11, 8, 8, 15, 14, 15, 14, 11, 14, 8, 11, 3, 16, 3, 14, 12, 16, 15, 9, 13, 9, 10, 16, 3, 15, 10, 16, 8, 16, 16, 12, 8, 14, 3, 15, 13, 9, 14, 11, 15, 8, 8, 15, 15, 3, 15, 16, 10, 16, 14, 13, 14, 13, 3, 10, 14, 14, 8, 10, 11, 16, 3, 15, 15, 8, 12, 9, 16, 11, 16, 9, 16, 15, 10, 9, 3, 14, 14, 13, 14, 8, 16, 3, 11, 9, 10, 16, 11, 3, 13, 15, 8, 10, 3, 10, 16, 3, 12, 15, 14, 13, 15, 16, 13, 16, 16, 8, 10, 9, 15, 13, 9, 13, 14, 10, 14, 13, 3, 10, 15, 13, 11, 14, 8, 13, 3, 16, 16, 16, 9, 13, 3, 11, 9, 11, 16, 15, 11, 12, 13, 12, 16, 8, 14, 12, 15, 9, 14, 3, 15, 12, 9, 14, 10, 8, 11, 13, 15, 11, 13, 11, 8, 16, 10, 13, 13, 14, 9, 16, 13, 3, 14, 14, 12, 13, 15, 3, 13, 10, 14, 9, 11, 11, 10, 15, 14, 15, 15, 10, 11, 3, 15, 9, 14, 11, 8, 10, 3, 15, 12, 10, 11, 15, 14, 8, 14, 11, 13, 13, 8, 8, 14, 14, 16, 14, 11, 14, 8, 10, 16, 13, 3, 16, 8, 12, 12, 15, 10, 16, 16, 3, 9, 13, 8, 15, 3, 13, 10, 11, 14, 16, 13, 9, 13, 12, 8, 13, 14, 16, 12, 14, 16, 16, 13, 16, 13, 13, 16, 16, 10, 8, 13, 16, 15, 15, 11, 13, 13, 14, 16, 3, 16, 11, 12, 12, 8, 10, 9, 15, 8, 3, 10, 16, 15, 11, 8, 11, 3, 11, 15, 13, 16, 12, 11, 14, 12, 11, 14, 12, 11, 16, 11, 12, 9, 16, 9, 10, 9, 14, 14, 14, 3, 15, 8, 14, 8, 8, 9, 8, 13, 16, 13, 12, 3, 10, 9, 8, 14, 13, 12, 14, 15, 14, 12, 14, 16, 8, 12, 8, 3, 11, 12, 8, 15, 9, 11, 8, 16, 3, 13, 14, 14, 11, 3, 9, 12, 14, 11, 14, 12, 8, 9, 3, 14, 8, 11, 16, 13, 12, 15, 12, 13, 12, 16, 8, 13, 8, 8, 9, 10, 15, 8, 16, 16, 8]\n",
            "Labels:\n",
            "['Na', 'Nd', 'Lc', 'Wa', 'Eb', 'Ac', 'Ta', 'Nb', 'Eb', 'Ea', 'Wc', 'Ea', 'Wa', 'Nb', 'Nb', 'Wd', 'Wb', 'La', 'Wb', 'Tb', 'Wb', 'Na', 'Wc', 'Na', 'Nc', 'La', 'Wa', 'Ed', 'Wa', 'Lc', 'Fd', 'Nc', 'Ea', 'Lb', 'La', 'Ac', 'Wb', 'Fc', 'La', 'Wa', 'Na', 'Nc', 'Ac', 'Wb', 'Fc', 'Wc', 'Tb', 'Wc', 'Wa', 'Wa', 'Eb', 'Nc', 'Na', 'Tc', 'Ed', 'Ab', 'Ea', 'Lb', 'Ff', 'Fa', 'Nc', 'Na', 'Ea', 'Wd', 'Aa', 'Wc', 'Wa', 'Ta', 'Wa', 'Fe', 'Ta', 'Ab', 'Ab', 'Ea', 'Ld', 'Ad', 'Tc', 'Nb', 'Ac', 'Fd', 'Wb', 'Fb', 'Fb', 'Aa', 'Aa', 'Ta', 'Wc', 'Ta', 'Wb', 'Eb', 'Lb', 'Ld', 'Td', 'Aa', 'Wa', 'Na', 'Wc', 'Fc', 'Tb', 'Fd', 'Td', 'Nc', 'Wb', 'Wc', 'Lb', 'La', 'Lb', 'Ea', 'Ab', 'Fb', 'La', 'Na', 'Tb', 'Nb', 'Lb', 'Nc', 'Aa', 'Lb', 'Nd', 'Ec', 'Ad', 'Nb', 'Lc', 'Nb', 'Tc', 'Tc', 'Ea', 'Fd', 'Fa', 'Wa', 'La', 'Fb', 'Fa', 'Nb', 'Wa', 'Ac', 'Wa', 'Ec', 'Ab', 'Ac', 'La', 'Lc', 'Nb', 'Ff', 'Lb', 'Tc', 'Nd', 'Ad', 'Fd', 'Tc', 'Ab', 'Wc', 'Ac', 'Ta', 'Tc', 'Fd', 'Lb', 'Fc', 'Wc', 'La', 'Ae', 'Wc', 'Lb', 'Wb', 'Aa', 'Ld', 'Lc', 'Fb', 'Wb', 'Ed', 'Fa', 'Ad', 'Aa', 'La', 'Wa', 'Aa', 'Wb', 'Tb', 'La', 'Ec', 'Wc', 'Tb', 'Tc', 'Wa', 'Ld', 'Wa', 'Nb', 'Wa', 'Ld', 'Wa', 'Wc', 'Tc', 'Fa', 'Eb', 'Ab', 'Fb', 'Ad', 'Lb', 'Fb', 'Fb', 'Lb', 'Ta', 'Wc', 'Nc', 'Fc', 'Ac', 'Wc', 'Wa', 'Wb', 'Ta', 'Ea', 'Wa', 'Lb', 'Wc', 'Ta', 'Fb', 'Wa', 'Nc', 'Td', 'Ab', 'Nd', 'Tb', 'Ac', 'Fd', 'Nb', 'Fa', 'Eb', 'Wb', 'Ab', 'Wc', 'Wc', 'Lb', 'Td', 'Na', 'Eb', 'Aa', 'Ea', 'Ad', 'Na', 'Ec', 'Nb', 'Tb', 'Ad', 'Wc', 'La', 'Ta', 'Nc', 'La', 'Ac', 'Tc', 'Ac', 'Na', 'Lb', 'Wa', 'Fd', 'Ab', 'Fd', 'La', 'Wb', 'Aa', 'Ec', 'Nb', 'Nb', 'Tc', 'Wb', 'Aa', 'Fc', 'Tc', 'Tb', 'Na', 'Fb', 'Ld', 'Lc', 'Ab', 'Wc', 'Nb', 'Tb', 'Wa', 'Wa', 'Wb', 'La', 'Aa', 'Ld', 'Wb', 'Fb', 'Fd', 'Wa', 'Lc', 'Na', 'Wb', 'Ta', 'Fc', 'Nb', 'Eb', 'Ta', 'Ac', 'Wd', 'Lb', 'Fc', 'Fa', 'Ab', 'Fa', 'Ea', 'Aa', 'Fd', 'Ac', 'Lb', 'La', 'Nc', 'Fd', 'Wc', 'Nb', 'Tb', 'Wb', 'Tc', 'Wc', 'Wc', 'Wa', 'Wb', 'Ac', 'Wa', 'Lb', 'Aa', 'Wa', 'La', 'Fb', 'Fb', 'Ec', 'Wb', 'Lb', 'Ea', 'Wc', 'Ad', 'Lc', 'Wd', 'Fa', 'Wb', 'La', 'Fa', 'Na', 'Lb', 'Ea', 'Ed', 'Na', 'Ld', 'Wa', 'Fa', 'Nc', 'Ec', 'Ad', 'Na', 'Td', 'Lb', 'Nc', 'Lc', 'Fd', 'Wc', 'Fd', 'Ad', 'Ta', 'Nc', 'Aa', 'Ac', 'Td', 'Na', 'Td', 'Td', 'Wc', 'Lb', 'Wb', 'Lc', 'Ad', 'Wb', 'Fe', 'Wc', 'Wa', 'Aa', 'La', 'Wb', 'Wb', 'Ta', 'Eb', 'Wa', 'Lc', 'Lc', 'Ta', 'Wa', 'Ac', 'Lb', 'Ab', 'Fc', 'Lc', 'La', 'Na', 'Wb', 'Aa', 'Ab', 'Wc', 'Wb', 'Lb', 'Wc', 'Fb', 'Td', 'Ta', 'Nb', 'Ld', 'Fa', 'Fa', 'Nc', 'Wb', 'Fe', 'Na', 'Eb', 'Na', 'Nc', 'Nc', 'Td', 'Na', 'Wa', 'Lb', 'Nc', 'Aa', 'Wa', 'Wb', 'Ec', 'Fd', 'Wa', 'Wd', 'Nb', 'Wc', 'Tb', 'Ea', 'Eb', 'Wa', 'Aa', 'Nb', 'Wb', 'Wc', 'Fd', 'Ac', 'Wb', 'Wa', 'Nd', 'Wa', 'Tb', 'Ta', 'Na', 'Tc', 'Wc', 'Nb', 'La', 'Lc', 'Wa', 'La', 'Fa', 'Wb', 'Nb', 'Ta', 'Wc', 'Ed', 'Wb', 'Wc', 'Tc', 'Na', 'La', 'Fe', 'Fd', 'Ea', 'Wa', 'Tc', 'Wc', 'Ec', 'Wa', 'Fa', 'Wb', 'Wb', 'Tc', 'Wb', 'Fd', 'Wd', 'Wb', 'Lc', 'Eb', 'Ac', 'Fa', 'Lc', 'Na', 'Fb', 'Nb', 'La', 'Ec', 'Wa', 'Lb', 'Ab', 'Nd', 'Fc', 'Lc', 'Ea', 'Fa', 'Aa', 'Fc', 'Na', 'Ab', 'Fc', 'Fd', 'Ac', 'Ea', 'Wd', 'Fc', 'Td', 'Aa', 'Tb', 'Nc', 'Ld', 'La', 'Wd', 'Wc', 'Nb', 'Lb', 'Nd', 'Ea', 'Nb', 'Ac', 'Ec', 'Na', 'Nc', 'Wd', 'Tc', 'Wa', 'Tb', 'Wb', 'La', 'Nb', 'La', 'Fd']\n",
            "\n",
            "\n",
            "MODEL: byols\n",
            "\n",
            "The shape of the normalised embeddings array is: torch.Size([535, 2048])\n",
            "Normalised Embeddings Array:\n",
            "tensor([[-0.7266, -0.2330,  0.0496,  ...,  2.7701,  1.4310,  0.8477],\n",
            "        [-1.8658, -0.2818, -0.9209,  ..., -1.0874,  0.3181,  1.8501],\n",
            "        [ 0.1219,  1.2081, -0.1654,  ..., -1.2156, -0.5150, -0.3162],\n",
            "        ...,\n",
            "        [-0.5254,  0.1002, -0.4655,  ..., -0.3963,  0.9170,  1.1318],\n",
            "        [ 0.3331,  1.6261,  1.0740,  ..., -0.6312,  0.5772,  0.7013],\n",
            "        [-0.0228,  0.4206, -1.4976,  ...,  0.7505,  0.6567,  1.0557]])\n",
            "\n",
            "Columnwise_mean:\n",
            "tensor([ 4.9021e-09, -2.2282e-09,  1.3369e-09,  ...,  3.5651e-09,\n",
            "        -4.4564e-09, -8.9128e-10])\n",
            "All means are less than 10**-6\n",
            "\n",
            "\n",
            "MODEL: compare\n",
            "\n",
            "The shape of the normalised embeddings array is: torch.Size([535, 6373])\n",
            "Normalised Embeddings Array:\n",
            "tensor([[ 0.7186, -0.6775,  1.4149,  ..., -0.1771, -0.3769, -0.5767],\n",
            "        [ 1.0062, -1.1394,  1.3564,  ..., -0.6842, -0.3111, -0.5985],\n",
            "        [ 0.7675, -1.1535, -0.9693,  ..., -0.6901, -0.6479, -0.7186],\n",
            "        ...,\n",
            "        [ 0.3679, -0.3497,  0.8879,  ..., -0.8911, -0.7736, -1.3200],\n",
            "        [ 0.6844,  0.9564, -0.9071,  ..., -0.3928, -0.5653, -0.4740],\n",
            "        [ 0.4123,  1.4933, -0.8997,  ..., -1.1244, -0.4278, -0.3012]])\n",
            "\n",
            "Columnwise_mean:\n",
            "tensor([-6.2390e-09,  3.5651e-09,  0.0000e+00,  ..., -1.7826e-09,\n",
            "         1.7826e-09, -5.3477e-09])\n",
            "All means are less than 10**-6\n",
            "\n",
            "\n",
            "MODEL: egemaps\n",
            "\n",
            "The shape of the normalised embeddings array is: torch.Size([535, 88])\n",
            "Normalised Embeddings Array:\n",
            "tensor([[-0.6338, -0.1196, -0.6927,  ..., -0.2478, -0.1250, -0.0849],\n",
            "        [-0.6947,  2.1488, -0.7537,  ..., -0.5495, -0.6450, -1.2178],\n",
            "        [-1.0974,  2.8947, -1.3372,  ...,  0.1322,  0.0693, -0.3936],\n",
            "        ...,\n",
            "        [-0.9193, -0.0362, -1.2850,  ..., -0.5178, -0.4674,  0.4791],\n",
            "        [-0.3995,  0.2697, -0.6997,  ..., -0.1426, -0.2879,  1.3000],\n",
            "        [-0.1915,  1.6517, -0.3309,  ...,  0.6587, -0.1683,  1.4103]])\n",
            "\n",
            "Columnwise_mean:\n",
            "tensor([ 0.0000e+00,  1.7826e-09,  1.7826e-09, -8.9128e-10, -6.2390e-09,\n",
            "        -2.2282e-09,  0.0000e+00, -4.0108e-09, -8.9128e-09,  1.5597e-09,\n",
            "        -2.6739e-09, -2.3396e-09,  6.4618e-09, -6.6846e-09, -4.4564e-09,\n",
            "         2.2282e-09, -2.6739e-09,  8.9128e-10, -4.4564e-10,  7.5759e-09,\n",
            "         6.2390e-09,  2.6739e-09, -5.3477e-09, -1.3369e-09, -3.5651e-09,\n",
            "         8.6900e-09, -2.2282e-09, -8.9128e-10,  8.9128e-10, -1.1141e-09,\n",
            "        -2.6739e-09,  1.7826e-09,  8.9128e-10,  2.2282e-09, -4.6792e-09,\n",
            "        -8.9128e-10,  0.0000e+00,  2.2282e-09, -1.7826e-09, -8.9128e-09,\n",
            "         5.3477e-09, -8.0216e-09,  0.0000e+00, -1.7826e-09, -4.7907e-09,\n",
            "        -2.8967e-09,  9.8041e-09, -2.6739e-09, -3.1195e-09,  4.4564e-10,\n",
            "        -4.4564e-10,  2.6739e-09, -3.5651e-09, -8.9128e-10,  1.7826e-09,\n",
            "        -4.4564e-10, -7.5759e-09,  7.1303e-09, -8.0216e-09, -3.5651e-09,\n",
            "         4.4564e-09,  4.4564e-09,  3.5651e-09,  2.6739e-09,  5.3477e-09,\n",
            "         0.0000e+00, -3.5651e-09,  5.3477e-09, -8.0216e-09, -4.7907e-09,\n",
            "         0.0000e+00, -3.5651e-09,  5.3477e-09, -7.1303e-09,  7.1303e-09,\n",
            "        -7.1303e-09, -1.7826e-09,  1.0695e-08,  0.0000e+00, -1.7826e-09,\n",
            "        -8.9128e-10,  7.1303e-09,  7.1303e-09,  0.0000e+00,  0.0000e+00,\n",
            "        -1.7826e-09, -5.3477e-09,  7.1303e-09])\n",
            "All means are less than 10**-6\n"
          ]
        }
      ],
      "source": [
        "# Phase_3: Speaker normalisation\n",
        "\n",
        "speakers = []\n",
        "labels = []\n",
        "\n",
        "for audio_file in audio_files_emo:\n",
        "  file_name = audio_file.split('/')[3]\n",
        "  speakers.append(int(file_name[:2]))\n",
        "  labels.append(file_name[5:7])\n",
        "\n",
        "\n",
        "# Verify speakers and labels array\n",
        "print('Speakers:')\n",
        "print(speakers)\n",
        "print('Labels:')\n",
        "print(labels)\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Normalised arrays\n",
        "# normalised_embeddings_wav2vec = speaker_normalisation(embeddings_array_wav2vec, speakers)\n",
        "# normalised_embeddings_hubert = speaker_normalisation(embeddings_array_hubert, speakers)\n",
        "normalised_embeddings_byols = speaker_normalisation(embeddings_array_byols, speakers)\n",
        "normalised_embeddings_compare= speaker_normalisation(embeddings_array_compare, speakers)\n",
        "normalised_embeddings_egemaps = speaker_normalisation(embeddings_array_egemaps, speakers)\n",
        "\n",
        "\n",
        "# Verifying normalised_embeddings_arrays\n",
        "normalised_embeddings_arrays = [normalised_embeddings_byols, normalised_embeddings_compare, normalised_embeddings_egemaps]\n",
        "\n",
        "for i in range(len(models)):\n",
        "  print()\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  print()\n",
        "  print('The shape of the normalised embeddings array is: {}'.format(normalised_embeddings_arrays[i].shape))\n",
        "  print('Normalised Embeddings Array:')\n",
        "  print((normalised_embeddings_arrays[i]))\n",
        "  print()\n",
        "  columnwise_mean = torch.mean(speaker_normalisation(embeddings_arrays[i], speakers), 0)\n",
        "  print('Columnwise_mean:')\n",
        "  print(columnwise_mean)\n",
        "  if torch.all(columnwise_mean < 10**(-6)):\n",
        "    print('All means are less than 10**-6')\n",
        "  else:\n",
        "    print('All means are NOT less than 10**-6')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-j5yIb13fsl"
      },
      "source": [
        "### Train Test splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A2mDMlFD4bG",
        "outputId": "7b63665d-1308-4d94-dade-3d359c1762b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "MODEL: byols\n",
            "\n",
            "The shape of X_train is: torch.Size([369, 2048])\n",
            "X_train\n",
            "tensor([[-0.7266, -0.2330,  0.0496,  ...,  2.7701,  1.4310,  0.8477],\n",
            "        [ 0.6627, -0.6566,  0.5286,  ...,  0.4009, -1.1438, -0.2275],\n",
            "        [ 0.9579, -0.8962, -1.1898,  ..., -2.1374, -1.0756, -0.2003],\n",
            "        ...,\n",
            "        [ 0.9588, -0.9793, -0.5004,  ...,  0.8546,  0.7931,  0.5545],\n",
            "        [-0.5254,  0.1002, -0.4655,  ..., -0.3963,  0.9170,  1.1318],\n",
            "        [ 0.3331,  1.6261,  1.0740,  ..., -0.6312,  0.5772,  0.7013]])\n",
            "\n",
            "The shape of X_test is: torch.Size([166, 2048])\n",
            "X_test\n",
            "tensor([[-0.4564, -1.7515, -1.2570,  ...,  0.0391, -0.0865,  1.8213],\n",
            "        [ 0.0677, -1.3450,  0.1907,  ..., -0.6493, -0.7612, -0.0036],\n",
            "        [ 0.2616,  0.3525,  1.3705,  ...,  0.1721,  0.2444,  0.1833],\n",
            "        ...,\n",
            "        [-0.3465, -0.7112,  0.3698,  ...,  0.8286,  0.1961,  0.2886],\n",
            "        [-0.5446, -0.3478, -0.2528,  ...,  2.0745, -0.5076,  0.3372],\n",
            "        [ 0.6637, -0.2886,  1.4136,  ..., -0.1432,  0.4254,  0.4458]])\n",
            "\n",
            "The length of y_train is: 369\n",
            "y_train\n",
            "['Na', 'Wd', 'Wa', 'Ff', 'Fe', 'Ab', 'Nc', 'La', 'Ab', 'Tb', 'Wa', 'La', 'Lc', 'Ff', 'Wc', 'Ac', 'La', 'Tb', 'Tb', 'Wc', 'Tc', 'Wa', 'Ta', 'Wc', 'Tb', 'Fd', 'Ab', 'Nb', 'Fd', 'Nb', 'Wa', 'Lc', 'Ta', 'Nc', 'Wc', 'Fe', 'Lc', 'Aa', 'Fe', 'Fd', 'Wc', 'Nb', 'Na', 'Fe', 'Fd', 'Wa', 'Tc', 'Na', 'Nb', 'Lb', 'Lc', 'Aa', 'La', 'Na', 'Wd', 'Tc', 'La', 'Fd', 'Lc', 'Ea', 'Wc', 'Nb', 'Na', 'Fd', 'Na', 'Tb', 'Na', 'Ed', 'Aa', 'Ta', 'Wc', 'Lb', 'Ea', 'Wb', 'Fa', 'Nb', 'Wa', 'Nd', 'Nb', 'Eb', 'Wb', 'Nb', 'Wb', 'Wb', 'Wd', 'Fa', 'Wa', 'Ea', 'Ed', 'Eb', 'La', 'Wd', 'La', 'Wb', 'Ta', 'Ea', 'Wb', 'Nd', 'Fd', 'Tb', 'Wa', 'Na', 'Wa', 'Wa', 'Ab', 'Lb', 'Ta', 'Ld', 'Aa', 'Nb', 'Wa', 'Ad', 'Aa', 'Lb', 'Fc', 'Wb', 'Fd', 'Aa', 'Ad', 'La', 'La', 'Wb', 'Tb', 'Aa', 'Wb', 'Wb', 'Lc', 'Fa', 'Fa', 'Na', 'Lb', 'La', 'Ac', 'Wb', 'Wa', 'Ea', 'Nb', 'Wb', 'Tb', 'Nd', 'Wb', 'Nc', 'Wa', 'Fc', 'Wc', 'Ab', 'Ld', 'Ac', 'Fd', 'Eb', 'Td', 'Fd', 'Td', 'Fb', 'Ad', 'Tc', 'Nd', 'Ab', 'Fc', 'Ae', 'Ld', 'Ta', 'Td', 'Na', 'Ad', 'Ld', 'Ld', 'Fb', 'Lc', 'Ac', 'Nc', 'Wc', 'Wc', 'Ad', 'Na', 'Ld', 'Td', 'Wc', 'Td', 'Lb', 'Nc', 'Wa', 'Aa', 'Wb', 'Fd', 'Wa', 'Na', 'Nb', 'Lc', 'Ec', 'Fc', 'Ab', 'Wd', 'Wd', 'Nb', 'Wc', 'La', 'Ac', 'Nb', 'Ld', 'Wc', 'Fb', 'La', 'Na', 'Ta', 'Ta', 'Ab', 'Wa', 'Ad', 'Wc', 'Wa', 'Wb', 'Lb', 'Wb', 'Ec', 'Nd', 'Ta', 'Wc', 'Wa', 'Wa', 'Wd', 'Ac', 'Fb', 'Wa', 'Ac', 'Td', 'Lb', 'Ea', 'Ac', 'Wa', 'Ed', 'Na', 'Wd', 'Aa', 'Wa', 'Ta', 'Ea', 'Ad', 'Fb', 'Na', 'Tb', 'Nb', 'Fd', 'Ac', 'Ac', 'Lb', 'Ad', 'Tc', 'Lb', 'Wc', 'Aa', 'Tc', 'Wa', 'Fb', 'Ta', 'Ac', 'Wc', 'Eb', 'Wb', 'Wc', 'Tc', 'Tc', 'Aa', 'Lc', 'Eb', 'Lb', 'Ea', 'Wc', 'Lb', 'Aa', 'Lb', 'Fa', 'Na', 'Nc', 'Fd', 'Aa', 'Ac', 'Na', 'Td', 'Ab', 'Wc', 'Wc', 'Wa', 'Tb', 'Tc', 'Wc', 'Ed', 'Wb', 'La', 'Wb', 'Wb', 'Eb', 'Fa', 'Fc', 'Na', 'Ea', 'Fc', 'Ld', 'Eb', 'Nb', 'Eb', 'Ea', 'Wb', 'Tb', 'Lb', 'La', 'Wb', 'La', 'Fa', 'Tc', 'Fb', 'Aa', 'Lb', 'Ea', 'Tc', 'La', 'Fa', 'Ab', 'Lb', 'Lc', 'Aa', 'Wb', 'La', 'Ec', 'Ad', 'Fb', 'Ea', 'Nc', 'Ab', 'Tb', 'Lb', 'Ea', 'Ta', 'Lb', 'Fd', 'Ab', 'Tb', 'Wa', 'Wa', 'Fd', 'Fc', 'Tb', 'Wb', 'Td', 'Wb', 'Wb', 'Wb', 'Wb', 'Fc', 'Wb', 'Fb', 'Td', 'Nb', 'Fa', 'Nc', 'Eb', 'Lb', 'Aa', 'Eb', 'Wa', 'La', 'Fa', 'Wc', 'Lc', 'Ea', 'Wc', 'Ec', 'Nb', 'La']\n",
            "\n",
            "The length of y_test is: 166\n",
            "y_test\n",
            "['Lc', 'Wb', 'Wc', 'Nc', 'Tc', 'Wa', 'Nb', 'Wb', 'Aa', 'Wb', 'Wc', 'La', 'Na', 'Nd', 'Ec', 'Tc', 'Fd', 'Wc', 'Wb', 'La', 'Wa', 'Ab', 'Nc', 'Wa', 'Fa', 'Td', 'Na', 'Wc', 'Nc', 'Tc', 'Nb', 'Aa', 'Fc', 'Wa', 'Fb', 'Lb', 'Nc', 'Ad', 'Ta', 'Ta', 'Nc', 'Tb', 'Wc', 'Wc', 'Fa', 'La', 'Fa', 'Fc', 'Nc', 'Ac', 'Ta', 'Nc', 'Ea', 'Nc', 'Fc', 'Ea', 'Wc', 'Lb', 'Wa', 'Fc', 'Lb', 'Lc', 'Fa', 'Wa', 'Fb', 'Ec', 'Ed', 'Wa', 'Lb', 'Wc', 'Ab', 'Ec', 'Ac', 'Wa', 'Ec', 'Nb', 'Fc', 'Fb', 'Wc', 'La', 'Wb', 'Lb', 'Fd', 'Tc', 'Wc', 'Ac', 'La', 'Ec', 'Fd', 'Ad', 'Lc', 'Wa', 'Wa', 'Lc', 'Na', 'Ab', 'Ta', 'Ld', 'Fa', 'Na', 'Td', 'Na', 'Wb', 'Tc', 'Ec', 'Fd', 'Aa', 'Nb', 'Nb', 'Nc', 'Wa', 'La', 'Wb', 'Ac', 'Wa', 'Eb', 'Nc', 'Ea', 'Ta', 'Wc', 'Wb', 'Nc', 'Lb', 'Nb', 'Nb', 'Tc', 'Ta', 'Fd', 'Fb', 'Wa', 'Ld', 'Wa', 'Fa', 'Eb', 'Fb', 'Lb', 'Wc', 'Ac', 'Nb', 'Ac', 'Na', 'Aa', 'Na', 'Wa', 'Ac', 'Fa', 'La', 'Fb', 'Wd', 'Wb', 'La', 'Ea', 'Ec', 'Lb', 'Aa', 'Lc', 'Na', 'Nc', 'Nb', 'Wa', 'Ac', 'Tc', 'Lc', 'Ab', 'Nd', 'Wb']\n",
            "\n",
            "\n",
            "MODEL: compare\n",
            "\n",
            "The shape of X_train is: torch.Size([380, 6373])\n",
            "X_train\n",
            "tensor([[ 0.7186, -0.6775,  1.4149,  ..., -0.1771, -0.3769, -0.5767],\n",
            "        [ 1.5505,  1.6193,  1.3313,  ...,  0.8082,  1.2003,  0.1106],\n",
            "        [ 0.8730, -0.7577, -1.0328,  ...,  1.6363,  1.1749,  0.2831],\n",
            "        ...,\n",
            "        [-0.4333, -0.1628, -0.5705,  ...,  0.1048,  0.4977,  0.5134],\n",
            "        [-0.1867, -1.1232, -0.9404,  ..., -0.3056, -0.4070, -0.9486],\n",
            "        [ 1.3109,  1.2893, -0.9347,  ...,  0.1739,  1.0070,  0.6068]])\n",
            "\n",
            "The shape of X_test is: torch.Size([155, 6373])\n",
            "X_test\n",
            "tensor([[-0.7290, -1.1326, -0.8627,  ..., -1.8961, -1.4835, -1.4704],\n",
            "        [ 1.4549, -1.3425,  2.1022,  ...,  0.8566,  1.0937,  0.7757],\n",
            "        [ 1.8466,  0.1012,  2.2295,  ...,  0.2707,  0.1507, -0.1330],\n",
            "        ...,\n",
            "        [-0.6917, -1.4135,  0.9972,  ...,  0.2067, -0.4819,  0.3312],\n",
            "        [ 0.3679, -0.3497,  0.8879,  ..., -0.8911, -0.7736, -1.3200],\n",
            "        [ 0.6844,  0.9564, -0.9071,  ..., -0.3928, -0.5653, -0.4740]])\n",
            "\n",
            "The length of y_train is: 380\n",
            "y_train\n",
            "['Na', 'Wd', 'Wa', 'Ff', 'Fe', 'Ab', 'Nc', 'La', 'Ab', 'Tb', 'Wa', 'La', 'Lc', 'Ff', 'Wc', 'Ac', 'La', 'Tb', 'Tb', 'Wc', 'Tc', 'Wa', 'Ta', 'Wc', 'Tb', 'Fd', 'Ab', 'Nb', 'Fd', 'Nb', 'Wa', 'Lc', 'Ta', 'Nc', 'Wc', 'Fe', 'Lc', 'Aa', 'Fe', 'Fd', 'Wc', 'Nb', 'Na', 'Fe', 'Fd', 'Wa', 'Tc', 'Na', 'Nb', 'Lb', 'Lc', 'Aa', 'La', 'Na', 'Wd', 'Tc', 'La', 'Fd', 'Lc', 'Ea', 'Wc', 'Nb', 'Na', 'Fd', 'Na', 'Tb', 'Na', 'Ed', 'Aa', 'Ta', 'Wc', 'Lb', 'Ea', 'Wb', 'Fa', 'Nb', 'Wa', 'Nd', 'Nb', 'Eb', 'Wb', 'Nb', 'Wb', 'Wb', 'Wd', 'Fa', 'Wa', 'Ea', 'Ed', 'Eb', 'La', 'Wd', 'La', 'Wb', 'Ta', 'Ea', 'Wb', 'Nd', 'Fd', 'Tb', 'Wa', 'Na', 'Wa', 'Wa', 'Ab', 'Lb', 'Ta', 'Ld', 'Aa', 'Nb', 'Wa', 'Ad', 'Aa', 'Lb', 'Fc', 'Wb', 'Fd', 'Aa', 'Ad', 'La', 'La', 'Wb', 'Tb', 'Aa', 'Wb', 'Wb', 'Lc', 'Fa', 'Fa', 'Na', 'Lb', 'La', 'Ac', 'Wb', 'Wa', 'Ea', 'Nb', 'Wb', 'Tb', 'Nd', 'Wb', 'Nc', 'Wa', 'Fc', 'Wc', 'Ab', 'Ld', 'Ac', 'Fd', 'Eb', 'Td', 'Fd', 'Td', 'Fb', 'Ad', 'Tc', 'Nd', 'Ab', 'Fc', 'Ae', 'Ld', 'Ta', 'Td', 'Na', 'Ad', 'Ld', 'Ld', 'Fb', 'Lc', 'Ac', 'Nc', 'Wc', 'Wc', 'Ad', 'Na', 'Ld', 'Td', 'Wc', 'Td', 'Lb', 'Nc', 'Wa', 'Aa', 'Wb', 'Fd', 'Wa', 'Na', 'Nb', 'Lc', 'Ec', 'Fc', 'Ab', 'Wd', 'Wd', 'Ac', 'Ta', 'Nc', 'Ea', 'Nc', 'Fc', 'Ea', 'Wc', 'Lb', 'Wa', 'Fc', 'Lb', 'Lc', 'Fa', 'Wa', 'Fb', 'Ec', 'Ed', 'Wa', 'Lb', 'Wc', 'Ab', 'Ec', 'Ac', 'Wa', 'Ec', 'Nb', 'Fc', 'Fb', 'Wc', 'La', 'Wb', 'Lb', 'Fd', 'Tc', 'Wc', 'Ac', 'La', 'Ec', 'Fd', 'Ad', 'Lc', 'Wa', 'Wa', 'Lc', 'Na', 'Ab', 'Ta', 'Ld', 'Fa', 'Na', 'Td', 'Na', 'Wb', 'Tc', 'Ec', 'Fd', 'Aa', 'Nb', 'Nb', 'Nc', 'Wa', 'Ed', 'Na', 'Wd', 'Aa', 'Wa', 'Ta', 'Ea', 'Ad', 'Fb', 'Na', 'Tb', 'Nb', 'Fd', 'Ac', 'Ac', 'Lb', 'Ad', 'Tc', 'Lb', 'Wc', 'Aa', 'Tc', 'Wa', 'Fb', 'Ta', 'Ac', 'Wc', 'Eb', 'Wb', 'Wc', 'Tc', 'Tc', 'Aa', 'Lc', 'Eb', 'Lb', 'Ea', 'Wc', 'Lb', 'Aa', 'Lb', 'Fa', 'Na', 'Nc', 'Fd', 'Aa', 'Ac', 'Na', 'Td', 'Ab', 'Wc', 'Wc', 'Wa', 'Tb', 'Tc', 'Wc', 'Ed', 'Wb', 'La', 'Wb', 'Wb', 'Eb', 'Fa', 'Fc', 'Na', 'Ea', 'Fc', 'Ld', 'Wa', 'La', 'Wb', 'Ac', 'Wa', 'Eb', 'Nc', 'Ea', 'Ta', 'Wc', 'Wb', 'Nc', 'Lb', 'Nb', 'Nb', 'Tc', 'Ta', 'Fd', 'Fb', 'Wa', 'Ld', 'Wa', 'Fa', 'Eb', 'Fb', 'Lb', 'Wc', 'Ac', 'Nb', 'Ac', 'Na', 'Aa', 'Na', 'Wa', 'Ac', 'Fa', 'La', 'Fb', 'Wd', 'Wb', 'La', 'Ea', 'Ec', 'Lb', 'Aa', 'Lc', 'Na', 'Nc', 'Nb', 'Wa', 'Ac', 'Tc', 'Lc', 'Ab', 'Nd', 'Wb']\n",
            "\n",
            "The length of y_test is: 155\n",
            "y_test\n",
            "['Lc', 'Wb', 'Wc', 'Nc', 'Tc', 'Wa', 'Nb', 'Wb', 'Aa', 'Wb', 'Wc', 'La', 'Na', 'Nd', 'Ec', 'Tc', 'Fd', 'Wc', 'Wb', 'La', 'Wa', 'Ab', 'Nc', 'Wa', 'Fa', 'Td', 'Na', 'Wc', 'Nc', 'Tc', 'Nb', 'Aa', 'Fc', 'Wa', 'Fb', 'Lb', 'Nc', 'Ad', 'Ta', 'Ta', 'Nc', 'Tb', 'Wc', 'Wc', 'Fa', 'La', 'Fa', 'Fc', 'Nc', 'Nb', 'Wc', 'La', 'Ac', 'Nb', 'Ld', 'Wc', 'Fb', 'La', 'Na', 'Ta', 'Ta', 'Ab', 'Wa', 'Ad', 'Wc', 'Wa', 'Wb', 'Lb', 'Wb', 'Ec', 'Nd', 'Ta', 'Wc', 'Wa', 'Wa', 'Wd', 'Ac', 'Fb', 'Wa', 'Ac', 'Td', 'Lb', 'Ea', 'Ac', 'Eb', 'Nb', 'Eb', 'Ea', 'Wb', 'Tb', 'Lb', 'La', 'Wb', 'La', 'Fa', 'Tc', 'Fb', 'Aa', 'Lb', 'Ea', 'Tc', 'La', 'Fa', 'Ab', 'Lb', 'Lc', 'Aa', 'Wb', 'La', 'Ec', 'Ad', 'Fb', 'Ea', 'Nc', 'Ab', 'Tb', 'Lb', 'Ea', 'Ta', 'Lb', 'Fd', 'Ab', 'Tb', 'Wa', 'Wa', 'Fd', 'Fc', 'Tb', 'Wb', 'Td', 'Wb', 'Wb', 'Wb', 'Wb', 'Fc', 'Wb', 'Fb', 'Td', 'Nb', 'Fa', 'Nc', 'Eb', 'Lb', 'Aa', 'Eb', 'Wa', 'La', 'Fa', 'Wc', 'Lc', 'Ea', 'Wc', 'Ec', 'Nb', 'La']\n",
            "\n",
            "\n",
            "MODEL: egemaps\n",
            "\n",
            "The shape of X_train is: torch.Size([387, 88])\n",
            "X_train\n",
            "tensor([[-1.1680,  0.6443, -1.1408,  ..., -0.7170, -0.7160,  0.1395],\n",
            "        [ 1.4690, -1.1250,  1.5759,  ..., -0.5934, -0.4067,  0.1759],\n",
            "        [ 1.1953, -0.1301,  1.0371,  ..., -0.7170, -0.5665, -0.0814],\n",
            "        ...,\n",
            "        [-0.4274, -0.2451, -0.3627,  ...,  0.7174, -0.5458,  0.6051],\n",
            "        [-0.9193, -0.0362, -1.2850,  ..., -0.5178, -0.4674,  0.4791],\n",
            "        [-0.3995,  0.2697, -0.6997,  ..., -0.1426, -0.2879,  1.3000]])\n",
            "\n",
            "The shape of X_test is: torch.Size([148, 88])\n",
            "X_test\n",
            "tensor([[-0.6338, -0.1196, -0.6927,  ..., -0.2478, -0.1250, -0.0849],\n",
            "        [ 1.2165, -0.6109,  1.3453,  ...,  0.1917, -0.2248, -0.8409],\n",
            "        [ 0.8306,  0.7529,  0.7614,  ..., -0.1579, -0.2998, -0.7433],\n",
            "        ...,\n",
            "        [-0.6326, -0.1744, -0.9668,  ...,  1.4164,  1.8020,  1.4883],\n",
            "        [ 0.0079,  1.9651, -0.6064,  ...,  1.2127,  1.8689, -0.6411],\n",
            "        [ 0.4954, -0.5557,  0.8351,  ..., -1.0696, -0.9308,  0.0563]])\n",
            "\n",
            "The length of y_train is: 387\n",
            "y_train\n",
            "['Lc', 'Wb', 'Wc', 'Nc', 'Tc', 'Wa', 'Nb', 'Wb', 'Aa', 'Wb', 'Wc', 'La', 'Na', 'Nd', 'Ec', 'Tc', 'Fd', 'Wc', 'Wb', 'La', 'Wa', 'Ab', 'Nc', 'Wa', 'Fa', 'Td', 'Na', 'Wc', 'Nc', 'Tc', 'Nb', 'Aa', 'Fc', 'Wa', 'Fb', 'Lb', 'Nc', 'Ad', 'Ta', 'Ta', 'Nc', 'Tb', 'Wc', 'Wc', 'Fa', 'La', 'Fa', 'Fc', 'Nc', 'Lc', 'Ea', 'Wc', 'Nb', 'Na', 'Fd', 'Na', 'Tb', 'Na', 'Ed', 'Aa', 'Ta', 'Wc', 'Lb', 'Ea', 'Wb', 'Fa', 'Nb', 'Wa', 'Nd', 'Nb', 'Eb', 'Wb', 'Nb', 'Wb', 'Wb', 'Wd', 'Fa', 'Wa', 'Ea', 'Ed', 'Eb', 'La', 'Wd', 'La', 'Wb', 'Ta', 'Ea', 'Wb', 'Nd', 'Fd', 'Tb', 'Wa', 'Na', 'Wa', 'Wa', 'Ab', 'Lb', 'Ta', 'Ld', 'Aa', 'Nb', 'Wa', 'Ad', 'Aa', 'Lb', 'Fc', 'Wb', 'Fd', 'Aa', 'Ad', 'La', 'La', 'Wb', 'Tb', 'Aa', 'Wb', 'Wb', 'Lc', 'Fa', 'Fa', 'Na', 'Lb', 'La', 'Ac', 'Wb', 'Wa', 'Ea', 'Nb', 'Wb', 'Tb', 'Ac', 'Ta', 'Nc', 'Ea', 'Nc', 'Fc', 'Ea', 'Wc', 'Lb', 'Wa', 'Fc', 'Lb', 'Lc', 'Fa', 'Wa', 'Fb', 'Ec', 'Ed', 'Wa', 'Lb', 'Wc', 'Ab', 'Ec', 'Ac', 'Wa', 'Ec', 'Nb', 'Fc', 'Fb', 'Wc', 'La', 'Wb', 'Lb', 'Fd', 'Tc', 'Wc', 'Ac', 'La', 'Ec', 'Fd', 'Ad', 'Lc', 'Wa', 'Wa', 'Lc', 'Na', 'Ab', 'Ta', 'Ld', 'Fa', 'Na', 'Td', 'Na', 'Wb', 'Tc', 'Ec', 'Fd', 'Aa', 'Nb', 'Nb', 'Nc', 'Wa', 'Ed', 'Na', 'Wd', 'Aa', 'Wa', 'Ta', 'Ea', 'Ad', 'Fb', 'Na', 'Tb', 'Nb', 'Fd', 'Ac', 'Ac', 'Lb', 'Ad', 'Tc', 'Lb', 'Wc', 'Aa', 'Tc', 'Wa', 'Fb', 'Ta', 'Ac', 'Wc', 'Eb', 'Wb', 'Wc', 'Tc', 'Tc', 'Aa', 'Lc', 'Eb', 'Lb', 'Ea', 'Wc', 'Lb', 'Aa', 'Lb', 'Fa', 'Na', 'Nc', 'Fd', 'Aa', 'Ac', 'Na', 'Td', 'Ab', 'Wc', 'Wc', 'Wa', 'Tb', 'Tc', 'Wc', 'Ed', 'Wb', 'La', 'Wb', 'Wb', 'Eb', 'Fa', 'Fc', 'Na', 'Ea', 'Fc', 'Ld', 'Wa', 'La', 'Wb', 'Ac', 'Wa', 'Eb', 'Nc', 'Ea', 'Ta', 'Wc', 'Wb', 'Nc', 'Lb', 'Nb', 'Nb', 'Tc', 'Ta', 'Fd', 'Fb', 'Wa', 'Ld', 'Wa', 'Fa', 'Eb', 'Fb', 'Lb', 'Wc', 'Ac', 'Nb', 'Ac', 'Na', 'Aa', 'Na', 'Wa', 'Ac', 'Fa', 'La', 'Fb', 'Wd', 'Wb', 'La', 'Ea', 'Ec', 'Lb', 'Aa', 'Lc', 'Na', 'Nc', 'Nb', 'Wa', 'Ac', 'Tc', 'Lc', 'Ab', 'Nd', 'Wb', 'Eb', 'Nb', 'Eb', 'Ea', 'Wb', 'Tb', 'Lb', 'La', 'Wb', 'La', 'Fa', 'Tc', 'Fb', 'Aa', 'Lb', 'Ea', 'Tc', 'La', 'Fa', 'Ab', 'Lb', 'Lc', 'Aa', 'Wb', 'La', 'Ec', 'Ad', 'Fb', 'Ea', 'Nc', 'Ab', 'Tb', 'Lb', 'Ea', 'Ta', 'Lb', 'Fd', 'Ab', 'Tb', 'Wa', 'Wa', 'Fd', 'Fc', 'Tb', 'Wb', 'Td', 'Wb', 'Wb', 'Wb', 'Wb', 'Fc', 'Wb', 'Fb', 'Td', 'Nb', 'Fa', 'Nc', 'Eb', 'Lb', 'Aa', 'Eb', 'Wa', 'La', 'Fa', 'Wc', 'Lc', 'Ea', 'Wc', 'Ec', 'Nb', 'La']\n",
            "\n",
            "The length of y_test is: 148\n",
            "y_test\n",
            "['Na', 'Wd', 'Wa', 'Ff', 'Fe', 'Ab', 'Nc', 'La', 'Ab', 'Tb', 'Wa', 'La', 'Lc', 'Ff', 'Wc', 'Ac', 'La', 'Tb', 'Tb', 'Wc', 'Tc', 'Wa', 'Ta', 'Wc', 'Tb', 'Fd', 'Ab', 'Nb', 'Fd', 'Nb', 'Wa', 'Lc', 'Ta', 'Nc', 'Wc', 'Fe', 'Lc', 'Aa', 'Fe', 'Fd', 'Wc', 'Nb', 'Na', 'Fe', 'Fd', 'Wa', 'Tc', 'Na', 'Nb', 'Lb', 'Lc', 'Aa', 'La', 'Na', 'Wd', 'Tc', 'La', 'Fd', 'Nd', 'Wb', 'Nc', 'Wa', 'Fc', 'Wc', 'Ab', 'Ld', 'Ac', 'Fd', 'Eb', 'Td', 'Fd', 'Td', 'Fb', 'Ad', 'Tc', 'Nd', 'Ab', 'Fc', 'Ae', 'Ld', 'Ta', 'Td', 'Na', 'Ad', 'Ld', 'Ld', 'Fb', 'Lc', 'Ac', 'Nc', 'Wc', 'Wc', 'Ad', 'Na', 'Ld', 'Td', 'Wc', 'Td', 'Lb', 'Nc', 'Wa', 'Aa', 'Wb', 'Fd', 'Wa', 'Na', 'Nb', 'Lc', 'Ec', 'Fc', 'Ab', 'Wd', 'Wd', 'Nb', 'Wc', 'La', 'Ac', 'Nb', 'Ld', 'Wc', 'Fb', 'La', 'Na', 'Ta', 'Ta', 'Ab', 'Wa', 'Ad', 'Wc', 'Wa', 'Wb', 'Lb', 'Wb', 'Ec', 'Nd', 'Ta', 'Wc', 'Wa', 'Wa', 'Wd', 'Ac', 'Fb', 'Wa', 'Ac', 'Td', 'Lb', 'Ea', 'Ac']\n"
          ]
        }
      ],
      "source": [
        "# Phase_3: Train Test splitting\n",
        "\n",
        "# X_train_wav2vec, X_test_wav2vec, y_train_wav2vec, y_test_wav2vec = split_train_test(normalised_embeddings_wav2vec, labels, speakers, test_size = 0.30)\n",
        "# X_train_hubert, X_test_hubert, y_train_hubert, y_test_hubert = split_train_test(normalised_embeddings_hubert, labels, speakers, test_size = 0.30)\n",
        "X_train_byols, X_test_byols, y_train_byols, y_test_byols = split_train_test(normalised_embeddings_byols, labels, speakers, test_size = 0.30)\n",
        "X_train_compare, X_test_compare, y_train_compare, y_test_compare = split_train_test(normalised_embeddings_compare, labels, speakers, test_size = 0.30)\n",
        "X_train_egemaps, X_test_egemaps, y_train_egemaps, y_test_egemaps = split_train_test(normalised_embeddings_egemaps, labels, speakers, test_size = 0.30)\n",
        "\n",
        "X_trains = [X_train_byols, X_train_compare, X_train_egemaps]\n",
        "X_tests = [X_test_byols, X_test_compare, X_test_egemaps]\n",
        "y_trains = [y_train_byols, y_train_compare, y_train_egemaps]\n",
        "y_tests = [y_test_byols, y_test_compare, y_test_egemaps]\n",
        "\n",
        "# Verify\n",
        "for i in range(len(models)):\n",
        "  print()\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  print()\n",
        "  print('The shape of X_train is: {}'.format(X_trains[i].shape))\n",
        "  print('X_train')\n",
        "  print(X_trains[i])\n",
        "  print()\n",
        "  print('The shape of X_test is: {}'.format(X_tests[i].shape))\n",
        "  print('X_test')\n",
        "  print(X_tests[i])\n",
        "  print()\n",
        "  print('The length of y_train is: {}'.format(len(y_trains[i])))\n",
        "  print('y_train')\n",
        "  print(y_trains[i])\n",
        "  print()\n",
        "  print('The length of y_test is: {}'.format(len(y_tests[i])))\n",
        "  print('y_test')\n",
        "  print(y_tests[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GOWXjEtE5J_"
      },
      "source": [
        "## 1. Logistic Regression\n",
        "\n",
        "Defining functions for hyperparameter tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLj0kbWmVZ3A"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_hyperparams(X_train, X_test, y_train, y_test):\n",
        "  logreg = LogisticRegression()\n",
        "  parameters = {'penalty' : ['l1','l2'], 'C': np.logspace(-4,2,7), 'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
        "  grid = GridSearchCV(logreg, param_grid = parameters, cv=5)                     \n",
        "  grid.fit(X_train,y_train)\n",
        "  print('Accuracy :',grid.best_score_)\n",
        "  print('Best Parameters: {}'.format(grid.best_params_))\n",
        "  print('Accuracy on test_set: {}'.format(grid.score(X_test, y_test)))\n",
        "  return grid.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fckGF6LiFKVI"
      },
      "source": [
        "Getting best hyperparameters and checking accuracy of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSIzZ9VKWvHv",
        "outputId": "9e6b8723-bf30-4392-d5f3-8e3a1123caab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MODEL: byols\n",
            "Accuracy : 0.3089966679007775\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Accuracy on test_set: 0.2469879518072289\n",
            "\n",
            "MODEL: compare\n",
            "Accuracy : 0.28157894736842104\n",
            "Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Accuracy on test_set: 0.1935483870967742\n",
            "\n",
            "MODEL: egemaps\n",
            "Accuracy : 0.2763902763902764\n",
            "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Accuracy on test_set: 0.18243243243243243\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(len(models)):\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  hyperparams = get_hyperparams(X_trains[i], X_tests[i], y_trains[i], y_tests[i])\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8gbYn8lFZsr"
      },
      "source": [
        "## 2. Support Vector Machines\n",
        "\n",
        "Hyperparameter Tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BaYeyZpHbytP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_hyperparams_svm(X_train, X_test, y_train, y_test):\n",
        "  svm = SVC()\n",
        "  parameters = {'C': np.logspace(-2,3,6), 'gamma': np.logspace(-5,2,8), 'degree':[1], 'kernel':['rbf','poly','sigmoid','linear']}\n",
        "  grid = GridSearchCV(svm, param_grid = parameters, cv=5)                     \n",
        "  grid.fit(X_train, y_train)\n",
        "  print('Accuracy:',grid.best_score_)\n",
        "  print('Best Parameters {}'.format(grid.best_params_))\n",
        "  print('Accuracy on test_set: {}'.format(grid.score(X_test, y_test)))\n",
        "  return grid.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2ukLRyCFna4"
      },
      "source": [
        "Getting best hyperparameters and checking accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5eTYOgHrZnbe",
        "outputId": "062c2767-0a25-471e-a2a9-fa3e97b53dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MODEL: byols\n",
            "Accuracy: 0.3089966679007775\n",
            "Best Parameters {'C': 10.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
            "Accuracy on test_set: 0.24096385542168675\n",
            "\n",
            "MODEL: compare\n",
            "Accuracy: 0.29473684210526313\n",
            "Best Parameters {'C': 100.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
            "Accuracy on test_set: 0.25806451612903225\n",
            "\n",
            "MODEL: egemaps\n",
            "Accuracy: 0.2921078921078921\n",
            "Best Parameters {'C': 0.01, 'degree': 1, 'gamma': 1e-05, 'kernel': 'linear'}\n",
            "Accuracy on test_set: 0.19594594594594594\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(len(models)):\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  hyperparams = get_hyperparams_svm(X_trains[i], X_tests[i], y_trains[i], y_tests[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQbBg3I3F3Fp"
      },
      "source": [
        "## 3. Random Forrest Regression\n",
        "\n",
        "Defining functions for hyperparameter tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UOhj_a94o13Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_hyperparams_rfr(X_train, X_test, y_train, y_test):\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(labels)\n",
        "  y_train = le.transform(y_train)\n",
        "  y_test = le.transform(y_test)\n",
        "\n",
        "  rfr = RandomForestRegressor()\n",
        "  parameters = {'n_estimators' : [50,100,200], 'max_features' : ['auto', 'log2', 'sqrt'], 'bootstrap' : [True, False]}\n",
        "  grid = GridSearchCV(rfr, param_grid = parameters, cv = 5)                     \n",
        "  grid.fit(X_train, y_train)\n",
        "  print('Accuracy:',grid.best_score_)\n",
        "  print('Best Parameters {}'.format(grid.best_params_))\n",
        "  print('Accuracy on test_set: {}'.format(grid.score(X_test, y_test)))\n",
        "  return grid.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW3GODbR9sYa"
      },
      "source": [
        "Getting best hyperparameters and checking accuracy of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhq-EBFp9OKj",
        "outputId": "8eefa1aa-58b0-428a-dca0-4863e542098e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL: byols\n",
            "Accuracy: 0.41201278530927415\n",
            "Best Parameters {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "Accuracy on test_set: 0.5508525826114563\n",
            "\n",
            "MODEL: egemaps\n",
            "Accuracy: 0.6096095153352803\n",
            "Best Parameters {'bootstrap': True, 'max_features': 'auto', 'n_estimators': 100}\n",
            "Accuracy on test_set: 0.532827692151189\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(0, len(models), 2):\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  hyperparams = get_hyperparams_rfr(X_trains[i], X_tests[i], y_trains[i], y_tests[i])\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frmTqsrL7_wZ"
      },
      "source": [
        "# Impoving Accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGe0BlERtXdj"
      },
      "source": [
        "### 1. Training on the all the embeddings after speaker normalisation (without spliting into training set and test set) <BR>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqjFzagu8-Kg",
        "outputId": "bf99b2b6-c945-4349-a836-b71f88288af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "MODEL: byols\n",
            "1. Logistic Regression:\n",
            "Accuracy : 0.302803738317757\n",
            "Best Parameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Accuracy on test_set: 0.9775700934579439\n",
            "2. Support Vector Machines:\n",
            "Accuracy: 0.308411214953271\n",
            "Best Parameters {'C': 0.01, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Accuracy on test_set: 0.9757009345794393\n",
            "3. Random Forest:\n",
            "Accuracy: 0.5541684524885591\n",
            "Best Parameters {'bootstrap': True, 'max_features': 'auto', 'n_estimators': 100}\n",
            "Accuracy on test_set: 0.9398802322093553\n",
            "\n",
            "\n",
            "MODEL: egemaps\n",
            "1. Logistic Regression:\n",
            "Accuracy : 0.27850467289719627\n",
            "Best Parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Accuracy on test_set: 0.9121495327102803\n",
            "2. Support Vector Machines:\n",
            "Accuracy: 0.2953271028037383\n",
            "Best Parameters {'C': 0.01, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
            "Accuracy on test_set: 0.8710280373831776\n",
            "3. Random Forest:\n",
            "Accuracy: 0.6511260030077498\n",
            "Best Parameters {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "Accuracy on test_set: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_trains = [normalised_embeddings_arrays[0], normalised_embeddings_arrays[1], normalised_embeddings_arrays[2]]\n",
        "y_trains = [labels, labels, labels]\n",
        "\n",
        "for i in range(0, len(models), 2):\n",
        "  print()\n",
        "  print()\n",
        "  print('MODEL: {}'.format(models[i]))\n",
        "  print('1. Logistic Regression:')\n",
        "  get_hyperparams(X_trains[i], X_trains[i], y_trains[i], y_trains[i])\n",
        "  print('2. Support Vector Machines:')\n",
        "  get_hyperparams_svm(X_trains[i], X_trains[i], y_trains[i], y_trains[i])\n",
        "  print('3. Random Forest:')\n",
        "  get_hyperparams_rfr(X_trains[i], X_trains[i], y_trains[i], y_trains[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TusdAY0rphr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "B48qMjEB-CLk",
        "OW6Yipn9MTLg",
        "bgIMNm01HGyZ",
        "frmTqsrL7_wZ"
      ],
      "name": "EmoDB_Phase_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGD5U2Ni5lrZ/LsHAMuAFc",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}