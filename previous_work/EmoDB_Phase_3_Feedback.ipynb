{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/EmoDB_Phase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziyDk4cxk1wh"
   },
   "source": [
    "# EmoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B48qMjEB-CLk"
   },
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hed_5ILyX0ia",
    "outputId": "5e03c8c7-ee28-48d8-ae64-9079007a52a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: speechbrain in /usr/local/lib/python3.7/dist-packages (0.5.12)\n",
      "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.11.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.96)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.8.1)\n",
      "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.11.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.7.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.60.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain) (4.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.21)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain) (0.2.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "fatal: destination path 'serab-byols' already exists and is not an empty directory.\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Obtaining file:///content/serab-byols\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.8.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.51.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.21.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.11.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.11.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (4.60.0)\n",
      "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.9)\n",
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (1.0.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from serab-byols==0.0.0) (0.4.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (21.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (2.1.9)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.1.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (0.10.3.post1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (1.7.3)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->serab-byols==0.0.0) (0.3.1)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->serab-byols==0.0.0) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->serab-byols==0.0.0) (57.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->serab-byols==0.0.0) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->serab-byols==0.0.0) (2.23.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->serab-byols==0.0.0) (1.4.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->serab-byols==0.0.0) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->serab-byols==0.0.0) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->serab-byols==0.0.0) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->serab-byols==0.0.0) (2.21)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->serab-byols==0.0.0) (4.1.1)\n",
      "Installing collected packages: serab-byols\n",
      "  Attempting uninstall: serab-byols\n",
      "    Found existing installation: serab-byols 0.0.0\n",
      "    Can't uninstall 'serab-byols'. No files were found to uninstall.\n",
      "  Running setup.py develop for serab-byols\n",
      "Successfully installed serab-byols-0.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tqdm==4.60.0 in /usr/local/lib/python3.7/dist-packages (4.60.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: opensmile in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
      "Requirement already satisfied: audinterface>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from opensmile) (0.9.0)\n",
      "Requirement already satisfied: audobject>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from opensmile) (0.7.3)\n",
      "Requirement already satisfied: audformat<2.0.0,>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from audinterface>=0.7.0->opensmile) (0.14.3)\n",
      "Requirement already satisfied: audresample<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from audinterface>=0.7.0->opensmile) (1.1.0)\n",
      "Requirement already satisfied: iso-639 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (0.4.5)\n",
      "Requirement already satisfied: oyaml in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (6.0)\n",
      "Requirement already satisfied: pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.3.5)\n",
      "Requirement already satisfied: iso3166 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.1.1)\n",
      "Requirement already satisfied: audeer<2.0.0,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.18.0)\n",
      "Requirement already satisfied: audiofile>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from audeer<2.0.0,>=1.18.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (4.60.0)\n",
      "Requirement already satisfied: sox in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.4.1)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (0.10.3.post1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from audobject>=0.6.1->opensmile) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (4.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.15.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain\n",
    "!pip install transformers\n",
    "!git clone https://github.com/GasserElbanna/serab-byols.git\n",
    "!python3 -m pip install -e ./serab-byols\n",
    "\n",
    "!pip install tqdm==4.60.0\n",
    "!pip install opensmile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aTY1RZ4UwCsG"
   },
   "outputs": [],
   "source": [
    "#FEEDBACK: organizing your packages is usually a good practice\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from random import sample\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import torch\n",
    "# import opensmile\n",
    "import serab_byols\n",
    "from transformers import Wav2Vec2Model, HubertModel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "2r74_jiSWxp9",
    "outputId": "75caaceb-5b8f-4763-980d-19bd8c47bc85"
   },
   "outputs": [],
   "source": [
    "! pip install -q kaggle\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "# Name directory\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW6Yipn9MTLg"
   },
   "source": [
    "# Phase 1 Functions: Loading and resampling audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ae5OWFUETeZC"
   },
   "outputs": [],
   "source": [
    "# Defining function for loading and resampling audio files\n",
    "def load_audio_files(audio_files, resampling_frequency=16000, audio_list=None):\n",
    "    '''\n",
    "    Loads and resamples audio files \n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    audio_files: List\n",
    "        The paths of the wav files \n",
    "    resampling_frequency: int\n",
    "        The frequency which all audios will be resampled to\n",
    "    audio_list: List\n",
    "        list of torch arrays of audios to which more audios need too be added, empty by default\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    audio_list: List\n",
    "        A list of torch arrays, one array for each audio file\n",
    "        \n",
    "    '''\n",
    "\n",
    "    # Making audio_list\n",
    "    if audio_list is None:\n",
    "        audio_list = []\n",
    "\n",
    "    # Resampling\n",
    "    for audio in tqdm(audio_files):\n",
    "        signal, fs = librosa.load(audio, sr=resampling_frequency)\n",
    "        audio_list.append(torch.from_numpy(signal))\n",
    "        \n",
    "    return audio_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0kPY4usMGbA"
   },
   "source": [
    "# Phase 2 Functions: Embedding Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP3vG54u9D-r"
   },
   "source": [
    "## Audio Embeddings Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "WCNer33gwaMl"
   },
   "outputs": [],
   "source": [
    "def audio_embeddings_model(model_name):\n",
    "    '''\n",
    "      Generates model for embedding extraction \n",
    "\n",
    "      Parameters\n",
    "      ------------\n",
    "      mode_name: string\n",
    "          The model to used, could be 'wav2vec', 'hubert' or 'hybrid_byols'\n",
    "\n",
    "      Returns\n",
    "      ------------\n",
    "      model: object\n",
    "\n",
    "    '''\n",
    "    if model_name=='wav2vec2':\n",
    "        model_hub = 'facebook/wav2vec2-large-960h-lv60-self'\n",
    "        model = Wav2Vec2Model.from_pretrained(model_hub, cache_dir='/om2/user/gelbanna/huggingface/')\n",
    "    elif model_name=='hubert':\n",
    "        model_hub = 'facebook/hubert-xlarge-ll60k'\n",
    "        model = HubertModel.from_pretrained(model_hub, cache_dir='/om2/user/gelbanna/huggingface/')\n",
    "    elif model_name=='hybrid_byols':\n",
    "        model_name = 'cvt'\n",
    "        checkpoint_path = \"/om2/user/gelbanna/serab-byols/checkpoints/cvt_s1-d1-e64_s2-d1-e256_s3-d1-e512_BYOLAs64x96-osandbyolaloss6373-e100-bs256-lr0003-rs42.pth\"\n",
    "        model = serab_byols.load_model(checkpoint_path, model_name)\n",
    "    elif model_name=='compare':\n",
    "        model = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "    elif model_name=='egemaps':\n",
    "        model = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "def audio_embeddings(audio_list, model_name, model, sampling_rate=16000):\n",
    "    '''\n",
    "      Loads and resamples audio files \n",
    "\n",
    "      Parameters\n",
    "      ------------\n",
    "      audio_list: list of arrays\n",
    "          A list of arrays, one array for each audio file\n",
    "      model_name: string\n",
    "          The model to used, could be 'wav2vec', 'hubert' or 'hybrid_byols'\n",
    "      model: object\n",
    "          The model generated by audio_embeddings_model function\n",
    "      n_feats: int\n",
    "          The number of features of each audio file, 6373 for 'compare' and 88 for 'egemaps'\n",
    "\n",
    "      Returns\n",
    "      ------------\n",
    "      embeddings_array: torch array\n",
    "          The array containg embeddings of all audio_files, dimension (number of audio files × n_feats)\n",
    "\n",
    "    '''\n",
    "    if model_name=='hybrid_byols':\n",
    "        embeddings_array = serab_byols.get_scene_embeddings(audio_list, model).detach().cpu()\n",
    "    else:\n",
    "        embeddings_list = []\n",
    "        #FEEDBACK: iterate across elements of the list instead of indices\n",
    "        for audio in tqdm(audio_list):\n",
    "            if model_name=='wav2vec2' or model_name=='hubert':\n",
    "                #FEEDBACK: use unsqueeze to expand tensor dim\n",
    "                embeddings = model(audio.unsqueeze(0).to('cuda')).last_hidden_state.mean(1)\n",
    "                embeddings_list.append(embeddings.squeeze(0).detach().cpu())\n",
    "            elif model_name=='compare' or model_name=='egemaps':\n",
    "                embeddings = model.process_signal(audio_list[i], sampling_rate)\n",
    "                embeddings_list.append(torch.tensor(embeddings.values[0], dtype=torch.float32))\n",
    "        embeddings_array = torch.stack(embeddings_list)\n",
    "    return embeddings_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgIMNm01HGyZ"
   },
   "source": [
    "# Phase 3 Functions: Downstream Task - Speech Emotion Recognotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91OM9gcMHWLN"
   },
   "source": [
    "## Speaker normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tlFL7hMDwiqk"
   },
   "outputs": [],
   "source": [
    "def speaker_normalisation(embeddings_array, speakers):\n",
    "    '''\n",
    "      Normalises embeddings_array for each speaker\n",
    "\n",
    "      Parameters\n",
    "      ------------\n",
    "      embeddings_array: torch tensor\n",
    "          The tensor of embeddings, one row for each audio file\n",
    "      speakers: List\n",
    "          The list of speakers\n",
    "\n",
    "      Returns\n",
    "      ------------\n",
    "      embeddings_array: torch tensor\n",
    "          The tensor containg normalised embeddings \n",
    "\n",
    "    '''\n",
    "    speaker_ids = set(speakers)\n",
    "    scaler = StandardScaler()\n",
    "    for speaker_id in speaker_ids:\n",
    "        speaker_embeddings_indices = np.where(np.array(speakers)==speaker_id)[0]\n",
    "        speaker_embeddings = embeddings_array[speaker_embeddings_indices,:]\n",
    "        normalised_speaker_embeddings = scaler.fit_transform(speaker_embeddings)\n",
    "        embeddings_array[speaker_embeddings_indices] = torch.tensor(normalised_speaker_embeddings).float()\n",
    "    return embeddings_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "of_JsmJIX34u"
   },
   "source": [
    "## Dividing into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "eP4XPE0TS42u"
   },
   "outputs": [],
   "source": [
    "def split_train_test(normalised_embeddings_array, labels, speakers, test_size = 0.30):\n",
    "    '''\n",
    "    Splits into training and testing set with different speakers\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    normalised_embeddings_array: torch tensor\n",
    "      The tensor containing normalised embeddings \n",
    "    labels: list of strings\n",
    "      The list of emotions corresponding to audio files\n",
    "    speakers: list of integers \n",
    "      The list of speakers\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    X_train: torch tensor\n",
    "    The normalised embeddings that will be used for training\n",
    "    X_test: torch tensor\n",
    "    The normalised embeddings that will be used for testing\n",
    "    y_train: list of strings\n",
    "    The labels that will be used for training\n",
    "    y_test: list of strings\n",
    "    The labels that will be used for testing\n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    # 10 speakers in this dataset\n",
    "    all_speakers = np.unique(speakers)\n",
    "    # 3 of the 10 total speakers\n",
    "    test_speakers = np.random.rand(len(all_speakers)) < test_size\n",
    "    test_speakers = all_speakers[test_speakers]\n",
    "    print(test_speakers)\n",
    "    test_speakers_indices = []\n",
    "    train_speakers_indices = []\n",
    "\n",
    "    for speaker in all_speakers:\n",
    "        if speaker in test_speakers:\n",
    "            speaker_indices = np.where(np.array(speakers)==speaker)[0]\n",
    "            test_speakers_indices.extend(speaker_indices)\n",
    "        else:\n",
    "            speaker_indices = np.where(np.array(speakers)==speaker)[0]\n",
    "            train_speakers_indices.extend(speaker_indices)\n",
    "\n",
    "    X_train = normalised_embeddings_array[train_speakers_indices]\n",
    "    X_test = normalised_embeddings_array[test_speakers_indices]\n",
    "\n",
    "    y_train = [0 for i in range(len(train_speakers_indices))]\n",
    "    y_test = [0 for i in range(len(test_speakers_indices))]\n",
    "\n",
    "    for i,index in enumerate(train_speakers_indices):\n",
    "        y_train[i] = labels[index]\n",
    "    for i,index in enumerate(test_speakers_indices):\n",
    "        y_test[i] = labels[index]\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_split_train_test(normalised_embeddings_array, labels, speakers, test_size = 0.30):\n",
    "    '''\n",
    "    Splits into training and testing set with different speakers\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    normalised_embeddings_array: torch tensor\n",
    "      The tensor containing normalised embeddings \n",
    "    labels: list of strings\n",
    "      The list of emotions corresponding to audio files\n",
    "    speakers: list of integers \n",
    "      The list of speakers\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    X_train: torch tensor\n",
    "    The normalised embeddings that will be used for training\n",
    "    X_test: torch tensor\n",
    "    The normalised embeddings that will be used for testing\n",
    "    y_train: list of strings\n",
    "    The labels that will be used for training\n",
    "    y_test: list of strings\n",
    "    The labels that will be used for testing\n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    #get all speakers\n",
    "    all_speakers = np.unique(speakers)\n",
    "    # pick randomly the test speakers\n",
    "    test_speakers_indices = np.random.rand(len(all_speakers)) < test_size\n",
    "    test_speakers = all_speakers[test_speakers_indices]\n",
    "    print(test_speakers)\n",
    "    \n",
    "    test_speakers_indices = []\n",
    "    train_speakers_indices = []\n",
    "\n",
    "    for speaker in all_speakers:\n",
    "        if speaker in test_speakers:\n",
    "            speaker_indices = np.where(np.array(speakers)==speaker)[0]\n",
    "            test_speakers_indices.extend(speaker_indices)\n",
    "        else:\n",
    "            speaker_indices = np.where(np.array(speakers)==speaker)[0]\n",
    "            train_speakers_indices.extend(speaker_indices)\n",
    "\n",
    "    X_train = normalised_embeddings_array[train_speakers_indices]\n",
    "    X_test = normalised_embeddings_array[test_speakers_indices]\n",
    "\n",
    "    y_train = [0 for i in range(len(train_speakers_indices))]\n",
    "    y_test = [0 for i in range(len(test_speakers_indices))]\n",
    "\n",
    "    for i,index in enumerate(train_speakers_indices):\n",
    "        y_train[i] = labels[index]\n",
    "    for i,index in enumerate(test_speakers_indices):\n",
    "        y_test[i] = labels[index]\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q5gqY6Zv7tF"
   },
   "source": [
    "# EmoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yibhy17jDoPL"
   },
   "source": [
    "# Phase 1: Loading Dataset/Preprocessing Audios/Extracting Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9Jncl071Q_z",
    "outputId": "ffb22e22-cd2d-403e-ac55-711b8aa7aa1f"
   },
   "outputs": [],
   "source": [
    "# Phase_1\n",
    "# Load dataset\n",
    "! kaggle datasets download -d piyushagni5/berlin-database-of-emotional-speech-emodb\n",
    "! unzip berlin-database-of-emotional-speech-emodb.zip\n",
    "\n",
    "# Resample dataset\n",
    "audio_files_emo = glob(os.path.join('/content/wav','*.wav'))\n",
    "audio_list_emo= load_audio_files(audio_files_emo, resampling_frequency=16000)\n",
    "\n",
    "\n",
    "# Verify phase_1\n",
    "print()\n",
    "print('number of audio files: {}'.format(len(audio_list_emo)))\n",
    "print(audio_list_emo[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 535/535 [00:00<00:00, 1294.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Resample dataset\n",
    "audio_files_emo = glob('/om2/user/gelbanna/datasets/emodb/wav/*.wav')\n",
    "audio_list_emo= load_audio_files(audio_files_emo, resampling_frequency=16000)\n",
    "labels = np.array(list(map(lambda x: os.path.basename(x).split('.')[0][-2], audio_files_emo)))\n",
    "speakers = np.array(list(map(lambda x: os.path.basename(x)[:2], audio_files_emo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 7\n",
      "Number of speakers: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of classes: {np.unique(labels).shape[0]}')\n",
    "print(f'Number of speakers: {np.unique(speakers).shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTaOghCkDlq9"
   },
   "source": [
    "# Phase 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvmZ0RwTDXCY",
    "outputId": "43bc87c6-2b67-4565-e5d5-ae9c91dc4dbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-960h-lv60-self were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 535/535 [00:16<00:00, 32.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 535/535 [00:35<00:00, 15.21it/s]\n",
      "Generating Embeddings...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 535/535 [00:02<00:00, 179.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Phase_2\n",
    "\n",
    "# Wav2vec\n",
    "model = audio_embeddings_model(model_name='wav2vec2')\n",
    "model.to('cuda')\n",
    "embeddings_array_wav2vec = audio_embeddings(audio_list_emo, model_name='wav2vec2', model=model)\n",
    "\n",
    "# Hubert\n",
    "model = audio_embeddings_model(model_name='hubert')\n",
    "model.to('cuda')\n",
    "embeddings_array_hubert = audio_embeddings(audio_list_emo, model_name='hubert', model=model)\n",
    "\n",
    "# Hybrid BYOLS\n",
    "model = audio_embeddings_model(model_name='hybrid_byols')\n",
    "model.to('cuda')\n",
    "embeddings_array_byols = audio_embeddings(audio_list_emo, model_name='hybrid_byols', model=model)\n",
    "\n",
    "# # EmoDB compare\n",
    "# model = audio_embeddings_model(model_name='compare')\n",
    "# embeddings_array_compare = audio_embeddings(audio_list_emo, model_name='compare', model=model)\n",
    "\n",
    "# # EmoDB egemaps\n",
    "# model = audio_embeddings_model(model_name='egemaps')\n",
    "# embeddings_array_egemaps = audio_embeddings(audio_list_emo, model_name='egemaps', model=model)\n",
    "\n",
    "# # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Verify Phase_2\n",
    "models = ['wav2vec', 'hubert', 'byols']\n",
    "# embeddings_arrays = [embeddings_array_byols, embeddings_array_compare, embeddings_array_egemaps]\n",
    "\n",
    "# for i in range(len(models)):\n",
    "#   print()\n",
    "#   print()\n",
    "#   print('MODEL: {}'.format(models[i]))\n",
    "#   print()\n",
    "#   print('The shape of the embeddings array is {}'.format(embeddings_arrays[i].shape))\n",
    "#   print('The embeddings array is: ')\n",
    "#   print((embeddings_arrays[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('wav2vec2_emodb_embeddings.npy', embeddings_array_wav2vec)\n",
    "np.save('hubert_emodb_embeddings.npy', embeddings_array_hubert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJP6eGZYDiB-"
   },
   "source": [
    "# Phase 3: Emotions Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I17090Zh3uPR"
   },
   "source": [
    "### Speaker normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uibu-ZnCDg_D",
    "outputId": "d1cee5ee-f30b-46c1-b930-52c16b612498"
   },
   "outputs": [],
   "source": [
    "# Phase_3: Speaker normalisation\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Normalised arrays\n",
    "normalised_embeddings_wav2vec = speaker_normalisation(embeddings_array_wav2vec, speakers)\n",
    "normalised_embeddings_hubert = speaker_normalisation(embeddings_array_hubert, speakers)\n",
    "normalised_embeddings_byols = speaker_normalisation(embeddings_array_byols, speakers)\n",
    "# normalised_embeddings_compare= speaker_normalisation(embeddings_array_compare, speakers)\n",
    "# normalised_embeddings_egemaps = speaker_normalisation(embeddings_array_egemaps, speakers)\n",
    "\n",
    "\n",
    "# # Verifying normalised_embeddings_arrays\n",
    "# normalised_embeddings_arrays = [normalised_embeddings_byols, normalised_embeddings_compare, normalised_embeddings_egemaps]\n",
    "\n",
    "# for i in range(len(models)):\n",
    "#   print()\n",
    "#   print()\n",
    "#   print('MODEL: {}'.format(models[i]))\n",
    "#   print()\n",
    "#   print('The shape of the normalised embeddings array is: {}'.format(normalised_embeddings_arrays[i].shape))\n",
    "#   print('Normalised Embeddings Array:')\n",
    "#   print((normalised_embeddings_arrays[i]))\n",
    "#   print()\n",
    "#   columnwise_mean = torch.mean(speaker_normalisation(embeddings_arrays[i], speakers), 0)\n",
    "#   print('Columnwise_mean:')\n",
    "#   print(columnwise_mean)\n",
    "#   if torch.all(columnwise_mean < 10**(-6)):\n",
    "#     print('All means are less than 10**-6')\n",
    "#   else:\n",
    "#     print('All means are NOT less than 10**-6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.130433e-08</td>\n",
       "      <td>-7.450581e-09</td>\n",
       "      <td>5.138331e-10</td>\n",
       "      <td>-1.027666e-08</td>\n",
       "      <td>1.523836e-08</td>\n",
       "      <td>2.569166e-08</td>\n",
       "      <td>-1.027666e-09</td>\n",
       "      <td>-5.587935e-09</td>\n",
       "      <td>2.569166e-09</td>\n",
       "      <td>1.541499e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.193664e-09</td>\n",
       "      <td>-1.027666e-09</td>\n",
       "      <td>1.027666e-08</td>\n",
       "      <td>-1.644266e-08</td>\n",
       "      <td>-1.027666e-09</td>\n",
       "      <td>7.964414e-09</td>\n",
       "      <td>-1.027666e-08</td>\n",
       "      <td>-7.193664e-09</td>\n",
       "      <td>2.055333e-09</td>\n",
       "      <td>-3.339915e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "      <td>1.008734e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.225183e+00</td>\n",
       "      <td>-2.284904e+00</td>\n",
       "      <td>-1.352574e+00</td>\n",
       "      <td>-1.364579e+00</td>\n",
       "      <td>-1.145783e+00</td>\n",
       "      <td>-2.153695e+00</td>\n",
       "      <td>-3.578148e+00</td>\n",
       "      <td>-1.773826e+00</td>\n",
       "      <td>-1.089894e+00</td>\n",
       "      <td>-1.387864e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.468272e+00</td>\n",
       "      <td>-1.382820e+00</td>\n",
       "      <td>-2.818651e+00</td>\n",
       "      <td>-2.140071e+00</td>\n",
       "      <td>-2.643727e+00</td>\n",
       "      <td>-3.125862e+00</td>\n",
       "      <td>-1.939040e+00</td>\n",
       "      <td>-1.897121e+00</td>\n",
       "      <td>-2.019144e+00</td>\n",
       "      <td>-3.166881e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.559227e-01</td>\n",
       "      <td>-7.229099e-01</td>\n",
       "      <td>-7.759885e-01</td>\n",
       "      <td>-5.295486e-01</td>\n",
       "      <td>-6.304909e-01</td>\n",
       "      <td>-6.809228e-01</td>\n",
       "      <td>-3.592648e-01</td>\n",
       "      <td>-8.331828e-01</td>\n",
       "      <td>-6.033129e-01</td>\n",
       "      <td>-5.477249e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.617871e-01</td>\n",
       "      <td>-5.668021e-01</td>\n",
       "      <td>-2.753242e-01</td>\n",
       "      <td>-6.936557e-01</td>\n",
       "      <td>-3.147959e-01</td>\n",
       "      <td>-2.680866e-03</td>\n",
       "      <td>-6.307088e-01</td>\n",
       "      <td>-7.623295e-01</td>\n",
       "      <td>-6.184093e-01</td>\n",
       "      <td>4.833220e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.330399e-01</td>\n",
       "      <td>2.694504e-02</td>\n",
       "      <td>-2.323687e-01</td>\n",
       "      <td>-1.623333e-01</td>\n",
       "      <td>-3.341815e-01</td>\n",
       "      <td>-1.054178e-01</td>\n",
       "      <td>2.278525e-01</td>\n",
       "      <td>1.392073e-03</td>\n",
       "      <td>-3.323258e-01</td>\n",
       "      <td>-2.381661e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.108566e-01</td>\n",
       "      <td>-2.854047e-01</td>\n",
       "      <td>2.788046e-01</td>\n",
       "      <td>-1.695397e-01</td>\n",
       "      <td>1.734242e-01</td>\n",
       "      <td>2.351782e-01</td>\n",
       "      <td>-1.582271e-02</td>\n",
       "      <td>-1.328953e-01</td>\n",
       "      <td>1.085909e-01</td>\n",
       "      <td>3.305354e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.217686e-01</td>\n",
       "      <td>8.228316e-01</td>\n",
       "      <td>3.601648e-01</td>\n",
       "      <td>1.138228e-01</td>\n",
       "      <td>1.208290e-01</td>\n",
       "      <td>5.951509e-01</td>\n",
       "      <td>6.083220e-01</td>\n",
       "      <td>5.735645e-01</td>\n",
       "      <td>1.156738e-01</td>\n",
       "      <td>1.532558e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.016827e-01</td>\n",
       "      <td>1.468292e-01</td>\n",
       "      <td>6.567787e-01</td>\n",
       "      <td>7.182398e-01</td>\n",
       "      <td>6.205806e-01</td>\n",
       "      <td>6.476696e-01</td>\n",
       "      <td>6.834063e-01</td>\n",
       "      <td>6.290811e-01</td>\n",
       "      <td>5.392800e-01</td>\n",
       "      <td>5.624104e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.902808e+00</td>\n",
       "      <td>1.954161e+00</td>\n",
       "      <td>2.671592e+00</td>\n",
       "      <td>3.384115e+00</td>\n",
       "      <td>3.204188e+00</td>\n",
       "      <td>2.619911e+00</td>\n",
       "      <td>2.091192e+00</td>\n",
       "      <td>2.568441e+00</td>\n",
       "      <td>3.062953e+00</td>\n",
       "      <td>3.430804e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.324081e+00</td>\n",
       "      <td>3.295449e+00</td>\n",
       "      <td>1.360760e+00</td>\n",
       "      <td>2.429671e+00</td>\n",
       "      <td>1.735096e+00</td>\n",
       "      <td>1.077066e+00</td>\n",
       "      <td>2.560689e+00</td>\n",
       "      <td>2.975641e+00</td>\n",
       "      <td>3.258163e+00</td>\n",
       "      <td>9.751491e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1             2             3             4     \\\n",
       "count  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01   \n",
       "mean  -1.130433e-08 -7.450581e-09  5.138331e-10 -1.027666e-08  1.523836e-08   \n",
       "std    1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00   \n",
       "min   -2.225183e+00 -2.284904e+00 -1.352574e+00 -1.364579e+00 -1.145783e+00   \n",
       "25%   -6.559227e-01 -7.229099e-01 -7.759885e-01 -5.295486e-01 -6.304909e-01   \n",
       "50%   -1.330399e-01  2.694504e-02 -2.323687e-01 -1.623333e-01 -3.341815e-01   \n",
       "75%    6.217686e-01  8.228316e-01  3.601648e-01  1.138228e-01  1.208290e-01   \n",
       "max    2.902808e+00  1.954161e+00  2.671592e+00  3.384115e+00  3.204188e+00   \n",
       "\n",
       "               5             6             7             8             9     \\\n",
       "count  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01   \n",
       "mean   2.569166e-08 -1.027666e-09 -5.587935e-09  2.569166e-09  1.541499e-09   \n",
       "std    1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00   \n",
       "min   -2.153695e+00 -3.578148e+00 -1.773826e+00 -1.089894e+00 -1.387864e+00   \n",
       "25%   -6.809228e-01 -3.592648e-01 -8.331828e-01 -6.033129e-01 -5.477249e-01   \n",
       "50%   -1.054178e-01  2.278525e-01  1.392073e-03 -3.323258e-01 -2.381661e-01   \n",
       "75%    5.951509e-01  6.083220e-01  5.735645e-01  1.156738e-01  1.532558e-01   \n",
       "max    2.619911e+00  2.091192e+00  2.568441e+00  3.062953e+00  3.430804e+00   \n",
       "\n",
       "       ...          1014          1015          1016          1017  \\\n",
       "count  ...  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01   \n",
       "mean   ... -7.193664e-09 -1.027666e-09  1.027666e-08 -1.644266e-08   \n",
       "std    ...  1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00   \n",
       "min    ... -3.468272e+00 -1.382820e+00 -2.818651e+00 -2.140071e+00   \n",
       "25%    ... -1.617871e-01 -5.668021e-01 -2.753242e-01 -6.936557e-01   \n",
       "50%    ...  2.108566e-01 -2.854047e-01  2.788046e-01 -1.695397e-01   \n",
       "75%    ...  7.016827e-01  1.468292e-01  6.567787e-01  7.182398e-01   \n",
       "max    ...  1.324081e+00  3.295449e+00  1.360760e+00  2.429671e+00   \n",
       "\n",
       "               1018          1019          1020          1021          1022  \\\n",
       "count  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01  5.800000e+01   \n",
       "mean  -1.027666e-09  7.964414e-09 -1.027666e-08 -7.193664e-09  2.055333e-09   \n",
       "std    1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00  1.008734e+00   \n",
       "min   -2.643727e+00 -3.125862e+00 -1.939040e+00 -1.897121e+00 -2.019144e+00   \n",
       "25%   -3.147959e-01 -2.680866e-03 -6.307088e-01 -7.623295e-01 -6.184093e-01   \n",
       "50%    1.734242e-01  2.351782e-01 -1.582271e-02 -1.328953e-01  1.085909e-01   \n",
       "75%    6.205806e-01  6.476696e-01  6.834063e-01  6.290811e-01  5.392800e-01   \n",
       "max    1.735096e+00  1.077066e+00  2.560689e+00  2.975641e+00  3.258163e+00   \n",
       "\n",
       "               1023  \n",
       "count  5.800000e+01  \n",
       "mean  -3.339915e-09  \n",
       "std    1.008734e+00  \n",
       "min   -3.166881e+00  \n",
       "25%    4.833220e-02  \n",
       "50%    3.305354e-01  \n",
       "75%    5.624104e-01  \n",
       "max    9.751491e-01  \n",
       "\n",
       "[8 rows x 1024 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "embeddings = pd.DataFrame(normalised_embeddings_wav2vec)\n",
    "df = pd.DataFrame({'Speaker': speakers, 'Label': labels})\n",
    "df = pd.concat([df, embeddings], axis=1)\n",
    "df.loc[df.Speaker == '08'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-j5yIb13fsl"
   },
   "source": [
    "### Train Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'BYOL_S': X_train_byols, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5A2mDMlFD4bG",
    "outputId": "7b63665d-1308-4d94-dade-3d359c1762b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11' '12' '13']\n",
      "['11' '12' '13']\n",
      "['11' '12' '13']\n"
     ]
    }
   ],
   "source": [
    "# Phase_3: Train Test splitting\n",
    "\n",
    "X_train_wav2vec, X_test_wav2vec, y_train_wav2vec, y_test_wav2vec = split_train_test(normalised_embeddings_wav2vec, labels, speakers, test_size = 0.30)\n",
    "X_train_hubert, X_test_hubert, y_train_hubert, y_test_hubert = split_train_test(normalised_embeddings_hubert, labels, speakers, test_size = 0.30)\n",
    "X_train_byols, X_test_byols, y_train_byols, y_test_byols = split_train_test(normalised_embeddings_byols, labels, speakers, test_size = 0.30)\n",
    "# X_train_compare, X_test_compare, y_train_compare, y_test_compare = split_train_test(normalised_embeddings_compare, labels, speakers, test_size = 0.30)\n",
    "# X_train_egemaps, X_test_egemaps, y_train_egemaps, y_test_egemaps = split_train_test(normalised_embeddings_egemaps, labels, speakers, test_size = 0.30)\n",
    "\n",
    "X_trains = [X_train_wav2vec, X_train_hubert, X_train_byols]\n",
    "X_tests = [X_test_wav2vec, X_test_hubert, X_test_byols]\n",
    "y_trains = [y_train_wav2vec, y_train_hubert, y_train_byols]\n",
    "y_tests = [y_test_wav2vec, y_test_hubert, y_test_byols]\n",
    "\n",
    "# # Verify\n",
    "# for i in range(len(models)):\n",
    "#   print()\n",
    "#   print()\n",
    "#   print('MODEL: {}'.format(models[i]))\n",
    "#   print()\n",
    "#   print('The shape of X_train is: {}'.format(X_trains[i].shape))\n",
    "#   print('X_train')\n",
    "#   print(X_trains[i])\n",
    "#   print()\n",
    "#   print('The shape of X_test is: {}'.format(X_tests[i].shape))\n",
    "#   print('X_test')\n",
    "#   print(X_tests[i])\n",
    "#   print()\n",
    "#   print('The length of y_train is: {}'.format(len(y_trains[i])))\n",
    "#   print('y_train')\n",
    "#   print(y_trains[i])\n",
    "#   print()\n",
    "#   print('The length of y_test is: {}'.format(len(y_tests[i])))\n",
    "#   print('y_test')\n",
    "#   print(y_tests[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GOWXjEtE5J_"
   },
   "source": [
    "## 1. Logistic Regression\n",
    "\n",
    "Defining functions for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "KLj0kbWmVZ3A"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_hyperparams(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression()\n",
    "    parameters = {'penalty' : ['l1','l2'], 'C': np.logspace(-4,2,7), 'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "    grid = GridSearchCV(logreg, param_grid = parameters, cv=5, scoring='recall_macro')                     \n",
    "    grid.fit(X_train,y_train)\n",
    "    print('Accuracy :',grid.best_score_)\n",
    "    print('Best Parameters: {}'.format(grid.best_params_))\n",
    "    print('Accuracy on test_set: {}'.format(grid.score(X_test, y_test)))\n",
    "    return grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fckGF6LiFKVI"
   },
   "source": [
    "Getting best hyperparameters and checking accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSIzZ9VKWvHv",
    "outputId": "9e6b8723-bf30-4392-d5f3-8e3a1123caab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: wav2vec\n",
      "Accuracy : 0.76695852184574\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy on test_set: 0.7697487295313382\n",
      "\n",
      "MODEL: hubert\n",
      "Accuracy : 0.9218635332921048\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy on test_set: 0.8796657793552204\n",
      "\n",
      "MODEL: byols\n",
      "Accuracy : 0.9020634920634922\n",
      "Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy on test_set: 0.769899975800597\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print()\n",
    "    print('MODEL: {}'.format(models[i]))\n",
    "    hyperparams = get_hyperparams(X_trains[i], X_tests[i], y_trains[i], y_tests[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8gbYn8lFZsr"
   },
   "source": [
    "## 2. Support Vector Machines\n",
    "\n",
    "Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BaYeyZpHbytP"
   },
   "outputs": [],
   "source": [
    "def get_hyperparams_svm(X_train, X_test, y_train, y_test):\n",
    "    svm = SVC()\n",
    "    parameters = {'C': np.logspace(-2,3,6), 'gamma': np.logspace(-5,2,8), 'degree':[1], 'kernel':['rbf','poly','sigmoid','linear']}\n",
    "    grid = GridSearchCV(svm, param_grid = parameters, cv=5)                     \n",
    "    grid.fit(X_train, y_train)\n",
    "    print('Accuracy:',grid.best_score_)\n",
    "    print('Best Parameters {}'.format(grid.best_params_))\n",
    "    print('Accuracy on test_set: {}'.format(grid.score(X_test, y_test)))\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2ukLRyCFna4"
   },
   "source": [
    "Getting best hyperparameters and checking accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5eTYOgHrZnbe",
    "outputId": "062c2767-0a25-471e-a2a9-fa3e97b53dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: wav2vec\n",
      "Accuracy: 0.6903622693096377\n",
      "Best Parameters {'C': 100.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "Accuracy on test_set: 0.7350993377483444\n",
      "\n",
      "MODEL: hubert\n",
      "Accuracy: 0.924606971975393\n",
      "Best Parameters {'C': 100.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "Accuracy on test_set: 0.9271523178807947\n",
      "\n",
      "MODEL: byols\n",
      "Accuracy: 0.8878673957621326\n",
      "Best Parameters {'C': 1.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "Accuracy on test_set: 0.8609271523178808\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print()\n",
    "    print('MODEL: {}'.format(models[i]))\n",
    "    hyperparams = get_hyperparams_svm(X_trains[i], X_tests[i], y_trains[i], y_tests[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQbBg3I3F3Fp"
   },
   "source": [
    "## 3. Random Forrest Regression\n",
    "\n",
    "Defining functions for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "UOhj_a94o13Z"
   },
   "outputs": [],
   "source": [
    "def get_hyperparams_rfr(X_train, X_test, y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    # le.fit(labels)\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.fit_transform(y_test)\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    parameters = {'n_estimators' : [50,100,200], 'max_features' : ['auto', 'log2', 'sqrt'], 'bootstrap' : [True, False]}\n",
    "    grid = GridSearchCV(rfr, param_grid = parameters, cv = 5)                     \n",
    "    grid.fit(X_train, y_train)\n",
    "    print('Accuracy:',grid.best_score_)\n",
    "    print('Best Parameters {}'.format(grid.best_params_))\n",
    "    print('Accuracy on test_set: {}'.format(grid.score(X_test, y_test)))\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW3GODbR9sYa"
   },
   "source": [
    "Getting best hyperparameters and checking accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yhq-EBFp9OKj",
    "outputId": "8eefa1aa-58b0-428a-dca0-4863e542098e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: wav2vec\n",
      "Accuracy: 0.10358126457749048\n",
      "Best Parameters {'bootstrap': True, 'max_features': 'auto', 'n_estimators': 50}\n",
      "Accuracy on test_set: 0.0750304361744698\n",
      "\n",
      "MODEL: hubert\n",
      "Accuracy: 0.4176771212522422\n",
      "Best Parameters {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Accuracy on test_set: 0.4825711051920767\n",
      "\n",
      "MODEL: byols\n",
      "Accuracy: 0.5073069256859946\n",
      "Best Parameters {'bootstrap': True, 'max_features': 'auto', 'n_estimators': 100}\n",
      "Accuracy on test_set: 0.4565980402160863\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print()\n",
    "    print('MODEL: {}'.format(models[i]))\n",
    "    hyperparams = get_hyperparams_rfr(X_trains[i], X_tests[i], y_trains[i], y_tests[i])  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNGD5U2Ni5lrZ/LsHAMuAFc",
   "collapsed_sections": [
    "B48qMjEB-CLk",
    "OW6Yipn9MTLg",
    "bgIMNm01HGyZ",
    "frmTqsrL7_wZ"
   ],
   "include_colab_link": true,
   "name": "EmoDB_Phase_3.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
