# Speech Emotion Recognition
Identifying emotions from speech using self supervised learning


## Demo files
- `speech_emotion_recognition_demo.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/Phase_1.ipynb) A demo containing all steps of speech emotion recoginition using the EmoDB dataset. It includes loading and resampling audio files, extracting metadata, extracting DL based and handcrafted features, speaker normalisation, hyperparameter tuning and getting classification reports for logistic regression, SVM and random forest classification
- `datasets_demo.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/Phase_2_new.ipynb) A demo for comparing results obtained using multiple datasets. It includes performing all the steps on the following open source datasets: CaFE (French), EmoDB (German), ShEMO (Persian), RAVDESS (English), CREMA-D (English), SAVEE (British English)

## Datasets
- <a href="http://emodb.bilderbar.info/index-1280.html">EmoDB Dataset</a>
- <a href="https://zenodo.org/record/1478765#.YvyXfexBy3I">Canadian French Emotion (CaFE)</a>
- <a href="https://github.com/mansourehk/ShEMO"> Persian Speech Emotion Detection Dataset (ShEMO) </a>
- <a href="https://zenodo.org/record/1188976#.YvyPHexBy3K">Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)</a>
- <a href="https://github.com/CheyneyComputerScience/CREMA-D">Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D)</a>
- <a href="http://kahlan.eps.surrey.ac.uk/savee/Database.html">Surrey Audio-Visual Expressed Emotion (SAVEE)</a>

## References
- https://arxiv.org/abs/2110.03414


