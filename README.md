# speech_emotion_recognition
Identifying emotions from speech using self supervised learning

- `Phase_1.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/Phase_1.ipynb) contains functions to load and resample the audiofiles from a given dataset
- `Phase_2_new.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/Phase_2_new.ipynb) contains functions to extract embeddings using wav2vec, hubert, hybrid BYOL-S and dsp features using opensmile
- `Phase_3.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/Phase_3.ipynb) contains functions to extract labels and do speaker normalisation
- `Updated_Phase_3.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/Updated_Phase_3.ipynb) adds a section on EmoDB dataset
- `EmoDB_Phase_3.ipynb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satvik-dixit/speech_emotion_recognition/blob/main/EmoDB_Phase_3.ipynb) All steps on EmoDB dataset
